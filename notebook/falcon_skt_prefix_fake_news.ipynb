{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c70db20-44f1-42a1-b91c-3e9f1f135957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ccf41-1785-4a80-8878-8ccb7ecd9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea39733-ab8d-4a7f-ad32-b955058a0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fake_news_filipino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11caa1a4-68ad-4d31-a832-5ba54c58edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2416fa6f-5f67-463c-bb41-c9d33595d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f20024-3f76-46a0-b609-4187b70391e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3741cc9f162443aeb4f059bb52316fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436cd9f17f7344259ec6f39fd058237d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Llama 2 Tokenizer\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b-instruct\", add_prefix_space=True)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "# col_to_delete = ['idx']\n",
    "col_to_delete = ['article']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['article'], truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bb39f5-21bd-436a-89d6-2326cf6120cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FalconConfig {\n",
       "  \"_name_or_path\": \"tiiuae/falcon-7b-instruct\",\n",
       "  \"alibi\": false,\n",
       "  \"apply_residual_connection_post_layernorm\": false,\n",
       "  \"architectures\": [\n",
       "    \"FalconForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"tiiuae/falcon-7b-instruct--configuration_falcon.FalconConfig\",\n",
       "    \"AutoModel\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconModel\",\n",
       "    \"AutoModelForCausalLM\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForCausalLM\",\n",
       "    \"AutoModelForQuestionAnswering\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForQuestionAnswering\",\n",
       "    \"AutoModelForSequenceClassification\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForSequenceClassification\",\n",
       "    \"AutoModelForTokenClassification\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForTokenClassification\"\n",
       "  },\n",
       "  \"bias\": false,\n",
       "  \"bos_token_id\": 11,\n",
       "  \"eos_token_id\": 11,\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_size\": 4544,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"falcon\",\n",
       "  \"multi_query\": true,\n",
       "  \"new_decoder_architecture\": false,\n",
       "  \"num_attention_heads\": 71,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_kv_heads\": 71,\n",
       "  \"parallel_attn\": true,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 65024\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model_name=\"tiiuae/falcon-7b-instruct\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189d12ea-d2dd-4097-9507-a6e9814d4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "config._name_or_path=model_name\n",
    "config.hidden_size=4544\n",
    "config.num_hidden_layers=32\n",
    "config.n_head=71\n",
    "config.num_labels=2\n",
    "config.pad_token_id=tokenizer.pad_token_id\n",
    "config.hidden_dropout = 0.1\n",
    "config.transform=False\n",
    "config.text='Classify the text as positive or negative, text:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fd10de-d7c3-43f5-ae13-b97a04874b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d41aa8fdf1471299daca3c22d08bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix sequence length:  11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f93168f1c0b404c917cd161ff3f901e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PrefixForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-7b-instruct and are newly initialized: ['score.bias', 'prompt_encoder.embedding.weight', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from falconSKT import  PrefixForSequenceClassification, PromptForSequenceClassification\n",
    "model = PrefixForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fc374d-21d7-4fdf-9c71-5c2163d13225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 6921779778\n",
      "Trainable Parameters: 59074\n",
      "Percentage Trainable: 0.00085345101830253578%\n"
     ]
    }
   ],
   "source": [
    "# Total number of parameters in the model\n",
    "total_parameters = model.num_parameters()\n",
    "\n",
    "# Total number of trainable parameters in the model\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Calculate the percentage of trainable parameters\n",
    "percentage_trainable = (trainable_parameters / total_parameters) * 100\n",
    "\n",
    "print(f\"Total Parameters: {total_parameters}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters}\")\n",
    "print(f\"Percentage Trainable: {percentage_trainable:.20f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54785b09-40c0-44cc-b4e5-88c6acb18755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from sklearn.metrics import r2_score, accuracy_score, matthews_corrcoef\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    logits = p.predictions\n",
    "    #print(\"logits\", logits)\n",
    "    #print(\"logits\", len(logits), len(logits[0]), len(logits[0][0]))\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    labels = p.label_ids\n",
    "    #print(\"labels\", labels)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "\n",
    "\n",
    "    return {\"acc\": accuracy}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./rfalcon_task_prefix_sk',\n",
    "    num_train_epochs=15,\n",
    "    do_eval=True,\n",
    "    #learning_rate=0.001,\n",
    "    #bf16=True,\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=20,\n",
    "\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps = 100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    #optim=\"paged_adamw_8bit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607817df-bb02-47ac-9a8d-42621382aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1935' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1935/1935 2:45:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.570703</td>\n",
       "      <td>0.778816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>0.477829</td>\n",
       "      <td>0.822430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.472900</td>\n",
       "      <td>0.433270</td>\n",
       "      <td>0.841121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>0.410608</td>\n",
       "      <td>0.858255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>0.855140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.380426</td>\n",
       "      <td>0.861371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.370605</td>\n",
       "      <td>0.864486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.364172</td>\n",
       "      <td>0.848910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.361236</td>\n",
       "      <td>0.870717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.350219</td>\n",
       "      <td>0.876947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.347772</td>\n",
       "      <td>0.873832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.341922</td>\n",
       "      <td>0.880062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.340248</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.333872</td>\n",
       "      <td>0.883178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.331356</td>\n",
       "      <td>0.884735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.329581</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.329276</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.881620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.339800</td>\n",
       "      <td>0.328018</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removed shared tensor {'prompt_encoder.transfromer.h.25.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.29.input_layernorm.bias', 'prompt_encoder.transfromer.h.15.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.20.input_layernorm.bias', 'prompt_encoder.transfromer.h.28.input_layernorm.weight', 'prompt_encoder.transfromer.h.31.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.1.self_attention.dense.weight', 'prompt_encoder.transfromer.h.26.self_attention.dense.weight', 'prompt_encoder.transfromer.h.2.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.5.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.input_layernorm.bias', 'prompt_encoder.transfromer.h.3.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.23.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.22.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.input_layernorm.weight', 'prompt_encoder.transfromer.h.28.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.15.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.22.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.30.input_layernorm.weight', 'prompt_encoder.transfromer.h.21.self_attention.dense.weight', 'prompt_encoder.transfromer.h.5.input_layernorm.bias', 'prompt_encoder.transfromer.h.17.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.29.input_layernorm.weight', 'prompt_encoder.transfromer.h.11.input_layernorm.bias', 'prompt_encoder.transfromer.h.2.input_layernorm.weight', 'prompt_encoder.transfromer.h.18.self_attention.dense.weight', 'prompt_encoder.transfromer.h.1.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.25.self_attention.dense.weight', 'prompt_encoder.transfromer.h.13.input_layernorm.bias', 'prompt_encoder.transfromer.h.21.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.20.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.23.input_layernorm.weight', 'prompt_encoder.transfromer.h.24.input_layernorm.weight', 'prompt_encoder.transfromer.h.26.input_layernorm.weight', 'prompt_encoder.transfromer.h.13.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.16.self_attention.dense.weight', 'prompt_encoder.transfromer.h.18.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.input_layernorm.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.5.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.0.input_layernorm.weight', 'prompt_encoder.transfromer.h.5.self_attention.dense.weight', 'prompt_encoder.transfromer.h.9.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.ln_f.bias', 'prompt_encoder.transfromer.h.24.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.10.input_layernorm.weight', 'prompt_encoder.transfromer.h.17.self_attention.dense.weight', 'prompt_encoder.transfromer.h.27.self_attention.dense.weight', 'prompt_encoder.transfromer.h.27.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.20.input_layernorm.weight', 'prompt_encoder.transfromer.h.22.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.10.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.27.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.self_attention.dense.weight', 'prompt_encoder.transfromer.h.28.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.24.self_attention.dense.weight', 'prompt_encoder.transfromer.h.22.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.7.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.15.input_layernorm.bias', 'prompt_encoder.transfromer.h.4.self_attention.dense.weight', 'prompt_encoder.transfromer.h.6.input_layernorm.bias', 'prompt_encoder.transfromer.h.4.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.21.input_layernorm.weight', 'prompt_encoder.transfromer.h.21.input_layernorm.bias', 'prompt_encoder.transfromer.h.30.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.31.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.6.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.10.self_attention.dense.weight', 'prompt_encoder.transfromer.h.9.input_layernorm.bias', 'prompt_encoder.transfromer.h.11.input_layernorm.weight', 'prompt_encoder.transfromer.word_embeddings.weight', 'prompt_encoder.transfromer.h.26.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.13.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.23.self_attention.dense.weight', 'prompt_encoder.transfromer.h.9.self_attention.dense.weight', 'prompt_encoder.transfromer.h.14.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.14.self_attention.dense.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.13.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.ln_f.weight', 'prompt_encoder.transfromer.h.8.input_layernorm.bias', 'prompt_encoder.transfromer.h.18.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.12.self_attention.dense.weight', 'prompt_encoder.transfromer.h.7.input_layernorm.weight', 'prompt_encoder.transfromer.h.21.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.9.input_layernorm.weight', 'prompt_encoder.transfromer.h.23.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.1.input_layernorm.weight', 'prompt_encoder.transfromer.h.29.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.4.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.8.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.6.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.7.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.8.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.24.input_layernorm.bias', 'prompt_encoder.transfromer.h.31.input_layernorm.bias', 'prompt_encoder.transfromer.h.18.input_layernorm.weight', 'prompt_encoder.transfromer.h.13.self_attention.dense.weight', 'prompt_encoder.transfromer.h.19.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.17.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.17.input_layernorm.bias', 'prompt_encoder.transfromer.h.12.input_layernorm.bias', 'prompt_encoder.transfromer.h.28.self_attention.dense.weight', 'prompt_encoder.transfromer.h.27.input_layernorm.bias', 'prompt_encoder.transfromer.h.11.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.27.input_layernorm.weight', 'prompt_encoder.transfromer.h.4.input_layernorm.weight', 'prompt_encoder.transfromer.h.11.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.3.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.29.self_attention.dense.weight', 'prompt_encoder.transfromer.h.30.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.6.input_layernorm.weight', 'prompt_encoder.transfromer.h.16.input_layernorm.bias', 'prompt_encoder.transfromer.h.14.input_layernorm.weight', 'prompt_encoder.transfromer.h.15.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.8.input_layernorm.weight', 'prompt_encoder.transfromer.h.21.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.30.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.8.self_attention.dense.weight', 'prompt_encoder.transfromer.h.19.input_layernorm.bias', 'prompt_encoder.transfromer.h.16.input_layernorm.weight', 'prompt_encoder.transfromer.h.1.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.28.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.31.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.10.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.25.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.31.input_layernorm.weight', 'prompt_encoder.transfromer.h.25.input_layernorm.bias', 'prompt_encoder.transfromer.h.9.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.14.input_layernorm.bias', 'prompt_encoder.transfromer.h.30.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.0.input_layernorm.bias', 'prompt_encoder.transfromer.h.15.self_attention.dense.weight', 'prompt_encoder.transfromer.h.20.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.input_layernorm.weight', 'prompt_encoder.transfromer.h.26.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.2.input_layernorm.bias', 'prompt_encoder.transfromer.h.7.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.23.input_layernorm.bias', 'prompt_encoder.transfromer.h.9.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.4.input_layernorm.bias', 'prompt_encoder.transfromer.h.30.input_layernorm.bias', 'prompt_encoder.transfromer.h.15.input_layernorm.weight', 'prompt_encoder.transfromer.h.7.input_layernorm.bias', 'prompt_encoder.transfromer.h.31.self_attention.dense.weight', 'prompt_encoder.transfromer.h.3.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.1.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.17.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.3.input_layernorm.weight', 'prompt_encoder.transfromer.h.26.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.10.input_layernorm.bias', 'prompt_encoder.transfromer.h.28.input_layernorm.bias', 'prompt_encoder.transfromer.h.22.input_layernorm.bias', 'prompt_encoder.transfromer.h.14.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.3.self_attention.dense.weight', 'prompt_encoder.transfromer.h.19.self_attention.dense.weight', 'prompt_encoder.transfromer.h.29.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.5.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.8.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.11.self_attention.dense.weight', 'prompt_encoder.transfromer.h.0.self_attention.dense.weight', 'prompt_encoder.transfromer.h.11.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.16.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.5.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.27.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.6.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.22.input_layernorm.weight', 'prompt_encoder.transfromer.h.17.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.self_attention.dense.weight', 'prompt_encoder.transfromer.h.23.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.6.self_attention.dense.weight', 'prompt_encoder.transfromer.h.3.input_layernorm.bias', 'prompt_encoder.transfromer.h.16.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.16.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.0.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.4.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.7.self_attention.dense.weight', 'prompt_encoder.transfromer.h.10.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.26.input_layernorm.bias', 'prompt_encoder.transfromer.h.29.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.1.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.mlp.dense_h_to_4h.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "Could not locate the best model at ./rfalcon_task_prefix_sk/checkpoint-1900/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1935, training_loss=0.4078879600347475, metrics={'train_runtime': 9928.1168, 'train_samples_per_second': 3.874, 'train_steps_per_second': 0.195, 'total_flos': 1.9572171877131264e+17, 'train_loss': 0.4078879600347475, 'epoch': 15.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics, #compute_metrics1,#compute_metrics_classification,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=7)],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14db848-66f2-4f1c-ba0f-4c733b3f3d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1913' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1913/1935 2:43:50 < 01:53, 0.19 it/s, Epoch 14.82/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.320502</td>\n",
       "      <td>0.884735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.314951</td>\n",
       "      <td>0.884735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.312580</td>\n",
       "      <td>0.889408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.308553</td>\n",
       "      <td>0.889408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.307433</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.298492</td>\n",
       "      <td>0.889408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.293765</td>\n",
       "      <td>0.890966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.287614</td>\n",
       "      <td>0.894081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.291719</td>\n",
       "      <td>0.889408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.285068</td>\n",
       "      <td>0.897196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.281815</td>\n",
       "      <td>0.898754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.284103</td>\n",
       "      <td>0.904984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.283747</td>\n",
       "      <td>0.901869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.275469</td>\n",
       "      <td>0.901869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.274462</td>\n",
       "      <td>0.903427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.274651</td>\n",
       "      <td>0.904984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.273636</td>\n",
       "      <td>0.904984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>0.253793</td>\n",
       "      <td>0.920984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.262530</td>\n",
       "      <td>0.911869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a4648-fcef-4fc1-a4b8-59c7b6eed7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
