{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1510cc-2c33-48ce-b22e-39a7df77e0f7",
      "metadata": {
        "id": "de1510cc-2c33-48ce-b22e-39a7df77e0f7"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1010b1-ee7d-4e50-9deb-d853bd99214d",
      "metadata": {
        "id": "2c1010b1-ee7d-4e50-9deb-d853bd99214d"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd5be269-962b-40e7-820c-4bd15233e7f5",
      "metadata": {
        "id": "bd5be269-962b-40e7-820c-4bd15233e7f5"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate datasets scikit-learn sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52654071-04b0-4623-9948-1d249877efcf",
      "metadata": {
        "id": "52654071-04b0-4623-9948-1d249877efcf"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"fake_news_filipino\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c5c9dc-d33e-4028-8893-b942400a4e91",
      "metadata": {
        "id": "57c5c9dc-d33e-4028-8893-b942400a4e91"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[\"train\"].train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694e8b2e-f0e9-4724-ac53-f2603d4d37b2",
      "metadata": {
        "id": "694e8b2e-f0e9-4724-ac53-f2603d4d37b2",
        "outputId": "18500dfa-3a52-434a-d62b-b35bd0616dec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'article'],\n",
              "        num_rows: 2564\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'article'],\n",
              "        num_rows: 642\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2154b825-24b1-4efc-9491-5f50d1e1abfe",
      "metadata": {
        "id": "2154b825-24b1-4efc-9491-5f50d1e1abfe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
        "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efec15cd-f9b0-4e8d-85e9-0cb9f456d00b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5007803f02c342b1aafbdee5b36a9183",
            "14af6d0dfb8b4b62b8be9e2cd22c18e5"
          ]
        },
        "id": "efec15cd-f9b0-4e8d-85e9-0cb9f456d00b",
        "outputId": "1b2d7f25-8c72-42e9-827b-95e7afd8593a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5007803f02c342b1aafbdee5b36a9183",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2564 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14af6d0dfb8b4b62b8be9e2cd22c18e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/642 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load Llama 2 Tokenizer\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b-instruct\", add_prefix_space=True)\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True\n",
        "# col_to_delete = ['idx']\n",
        "col_to_delete = ['article']\n",
        "\n",
        "def preprocessing_function(examples):\n",
        "    return tokenizer(examples['article'], truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
        "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d390576a-c7ba-43e2-ab0a-efdeb54990a7",
      "metadata": {
        "id": "d390576a-c7ba-43e2-ab0a-efdeb54990a7",
        "outputId": "e7e6d8f4-62da-4a1a-f6f0-28972036831c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2564\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 642\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70c0b90-e696-4b64-b453-b12a9d2f656d",
      "metadata": {
        "id": "a70c0b90-e696-4b64-b453-b12a9d2f656d",
        "outputId": "04bf83a0-a78b-42e3-e22e-9da8c2538cc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FalconConfig {\n",
              "  \"_name_or_path\": \"tiiuae/falcon-7b-instruct\",\n",
              "  \"alibi\": false,\n",
              "  \"apply_residual_connection_post_layernorm\": false,\n",
              "  \"architectures\": [\n",
              "    \"FalconForCausalLM\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"auto_map\": {\n",
              "    \"AutoConfig\": \"tiiuae/falcon-7b-instruct--configuration_falcon.FalconConfig\",\n",
              "    \"AutoModel\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconModel\",\n",
              "    \"AutoModelForCausalLM\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForCausalLM\",\n",
              "    \"AutoModelForQuestionAnswering\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForQuestionAnswering\",\n",
              "    \"AutoModelForSequenceClassification\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForSequenceClassification\",\n",
              "    \"AutoModelForTokenClassification\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForTokenClassification\"\n",
              "  },\n",
              "  \"bias\": false,\n",
              "  \"bos_token_id\": 11,\n",
              "  \"eos_token_id\": 11,\n",
              "  \"hidden_dropout\": 0.0,\n",
              "  \"hidden_size\": 4544,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"max_position_embeddings\": 2048,\n",
              "  \"model_type\": \"falcon\",\n",
              "  \"multi_query\": true,\n",
              "  \"new_decoder_architecture\": false,\n",
              "  \"num_attention_heads\": 71,\n",
              "  \"num_hidden_layers\": 32,\n",
              "  \"num_kv_heads\": 71,\n",
              "  \"parallel_attn\": true,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"torch_dtype\": \"bfloat16\",\n",
              "  \"transformers_version\": \"4.36.2\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 65024\n",
              "}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoConfig\n",
        "model_name=\"tiiuae/falcon-7b-instruct\"\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5805e914-c233-434e-af47-5cfa056fa1b9",
      "metadata": {
        "id": "5805e914-c233-434e-af47-5cfa056fa1b9"
      },
      "outputs": [],
      "source": [
        "config._name_or_path=model_name\n",
        "config.hidden_size=4544\n",
        "config.num_hidden_layers=32\n",
        "config.n_head=71\n",
        "config.num_labels=2\n",
        "config.pad_token_id=tokenizer.pad_token_id\n",
        "config.hidden_dropout = 0.1\n",
        "config.transform=False\n",
        "config.text='classify the text as positive or negative, text:'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3020a8-b7b7-4ff7-985c-e5b573dcfe82",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "804588cd5a634fca8a6de88498a13901",
            "cbd7eb57e04c4c0f975edfe205dc0ee0"
          ]
        },
        "id": "6c3020a8-b7b7-4ff7-985c-e5b573dcfe82",
        "outputId": "665d3982-a2d6-4da3-b674-0f645bec1d13"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "804588cd5a634fca8a6de88498a13901",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt sequence length:  11\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbd7eb57e04c4c0f975edfe205dc0ee0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PromptForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-7b-instruct and are newly initialized: ['score.weight', 'prompt_encoder.embedding.weight', 'score.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from falconSKT import  PrefixForSequenceClassification, PromptForSequenceClassification\n",
        "model = PromptForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0766c3dd-9068-415d-a203-7ab14de101e9",
      "metadata": {
        "id": "0766c3dd-9068-415d-a203-7ab14de101e9",
        "outputId": "5fe435ac-850c-4e51-b974-976f71544568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Parameters: 6921779778\n",
            "Trainable Parameters: 59074\n",
            "Percentage Trainable: 0.00085345101830253578%\n"
          ]
        }
      ],
      "source": [
        "# Total number of parameters in the model\n",
        "total_parameters = model.num_parameters()\n",
        "\n",
        "# Total number of trainable parameters in the model\n",
        "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Calculate the percentage of trainable parameters\n",
        "percentage_trainable = (trainable_parameters / total_parameters) * 100\n",
        "\n",
        "print(f\"Total Parameters: {total_parameters}\")\n",
        "print(f\"Trainable Parameters: {trainable_parameters}\")\n",
        "print(f\"Percentage Trainable: {percentage_trainable:.20f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97598ece-04d3-437f-a348-efec246b44ad",
      "metadata": {
        "id": "97598ece-04d3-437f-a348-efec246b44ad"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
        "from sklearn.metrics import r2_score, accuracy_score, matthews_corrcoef\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    logits = p.predictions\n",
        "    #print(\"logits\", logits)\n",
        "    #print(\"logits\", len(logits), len(logits[0]), len(logits[0][0]))\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    labels = p.label_ids\n",
        "    #print(\"labels\", labels)\n",
        "\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "\n",
        "\n",
        "    return {\"acc\": accuracy}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./rfalcon_task_prompt',\n",
        "    num_train_epochs=10,\n",
        "    do_eval=True,\n",
        "    #learning_rate=0.001,\n",
        "    #bf16=True,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=10,\n",
        "\n",
        "    logging_dir='./logs',\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps = 100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    #optim=\"paged_adamw_8bit\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9457939b-b951-4802-84b3-9cf119fad441",
      "metadata": {
        "id": "9457939b-b951-4802-84b3-9cf119fad441",
        "outputId": "bd4cff37-b07b-4973-a572-a17aa0dd6c41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 642\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19045187-8b75-4cb2-bff4-2acc3c0a5b1c",
      "metadata": {
        "id": "19045187-8b75-4cb2-bff4-2acc3c0a5b1c",
        "outputId": "7a13e7fc-2493-4ccf-e235-ad80bcab4787"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2570' max='2570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2570/2570 2:26:32, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.746000</td>\n",
              "      <td>0.609614</td>\n",
              "      <td>0.672897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.563100</td>\n",
              "      <td>0.517491</td>\n",
              "      <td>0.830218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.518100</td>\n",
              "      <td>0.491138</td>\n",
              "      <td>0.766355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.481200</td>\n",
              "      <td>0.452652</td>\n",
              "      <td>0.827103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.450700</td>\n",
              "      <td>0.436989</td>\n",
              "      <td>0.848910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.414144</td>\n",
              "      <td>0.858255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.423000</td>\n",
              "      <td>0.404807</td>\n",
              "      <td>0.825545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.415300</td>\n",
              "      <td>0.399259</td>\n",
              "      <td>0.825545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.411100</td>\n",
              "      <td>0.380693</td>\n",
              "      <td>0.853583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.399000</td>\n",
              "      <td>0.374257</td>\n",
              "      <td>0.864486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.408700</td>\n",
              "      <td>0.373519</td>\n",
              "      <td>0.838006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.381000</td>\n",
              "      <td>0.361656</td>\n",
              "      <td>0.872274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.361800</td>\n",
              "      <td>0.357698</td>\n",
              "      <td>0.866044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.377400</td>\n",
              "      <td>0.362546</td>\n",
              "      <td>0.838006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.379200</td>\n",
              "      <td>0.352081</td>\n",
              "      <td>0.878505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.387900</td>\n",
              "      <td>0.347127</td>\n",
              "      <td>0.869159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.362800</td>\n",
              "      <td>0.344290</td>\n",
              "      <td>0.878505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.348800</td>\n",
              "      <td>0.342784</td>\n",
              "      <td>0.870717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.346900</td>\n",
              "      <td>0.341128</td>\n",
              "      <td>0.870717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.357600</td>\n",
              "      <td>0.338499</td>\n",
              "      <td>0.878505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.369700</td>\n",
              "      <td>0.337138</td>\n",
              "      <td>0.880062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.335898</td>\n",
              "      <td>0.883178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.346800</td>\n",
              "      <td>0.335986</td>\n",
              "      <td>0.873832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.334519</td>\n",
              "      <td>0.883178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.351200</td>\n",
              "      <td>0.334150</td>\n",
              "      <td>0.883178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the best model at ./rfalcon_task_prompt/checkpoint-2500/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2570, training_loss=0.4115899720544481, metrics={'train_runtime': 8794.6864, 'train_samples_per_second': 2.915, 'train_steps_per_second': 0.292, 'total_flos': 1.3048114584754176e+17, 'train_loss': 0.4115899720544481, 'epoch': 10.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        "    compute_metrics=compute_metrics, #compute_metrics1,#compute_metrics_classification,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=7)],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bd9628-dc2e-4441-8738-6f28b5ed74f7",
      "metadata": {
        "id": "f9bd9628-dc2e-4441-8738-6f28b5ed74f7",
        "outputId": "fce5cb12-f82b-484f-a558-1fa42ae3d528"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1601' max='2570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1601/2570 1:30:03 < 54:34, 0.30 it/s, Epoch 6.23/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.349300</td>\n",
              "      <td>0.328621</td>\n",
              "      <td>0.886293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.356400</td>\n",
              "      <td>0.321570</td>\n",
              "      <td>0.889408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>0.315313</td>\n",
              "      <td>0.897196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.333600</td>\n",
              "      <td>0.312389</td>\n",
              "      <td>0.897196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.331400</td>\n",
              "      <td>0.319523</td>\n",
              "      <td>0.880062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.306400</td>\n",
              "      <td>0.309928</td>\n",
              "      <td>0.890966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.303190</td>\n",
              "      <td>0.887850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.327500</td>\n",
              "      <td>0.307578</td>\n",
              "      <td>0.875389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.328900</td>\n",
              "      <td>0.295829</td>\n",
              "      <td>0.903427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.317000</td>\n",
              "      <td>0.294327</td>\n",
              "      <td>0.897196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.339400</td>\n",
              "      <td>0.293950</td>\n",
              "      <td>0.894081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.309900</td>\n",
              "      <td>0.288011</td>\n",
              "      <td>0.904984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.290200</td>\n",
              "      <td>0.287029</td>\n",
              "      <td>0.909657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.319300</td>\n",
              "      <td>0.296192</td>\n",
              "      <td>0.880062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.309800</td>\n",
              "      <td>0.283835</td>\n",
              "      <td>0.904984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/65 00:42 < 00:28, 0.90 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cf5237-4f35-4592-beb7-28a80d52d99e",
      "metadata": {
        "id": "56cf5237-4f35-4592-beb7-28a80d52d99e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}