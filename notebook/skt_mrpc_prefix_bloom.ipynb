{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52654071-04b0-4623-9948-1d249877efcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaae9f51-b77e-4e05-80a0-051b12d6f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\",\"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb831da5-9a41-4aee-a132-65e0eff6d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd1d1a4-aec3-4a69-a129-68553964a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "model_name=\"bigscience/bloomz-7b1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31837a8f-ebe8-4611-86f9-fe3a00510e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "# col_to_delete = ['idx']\n",
    "col_to_delete = ['sentence1','sentence2']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['sentence1'], examples['sentence2'])\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "\n",
    "# tokenized_test_dataset = test_dataset.map(preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "# tokenized_train_dataset.set_format(\"torch\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb88865-8ca4-48be-bfeb-762a624d95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5142e3-0546-4edb-8b8b-c314c4ba3b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomConfig {\n",
       "  \"_name_or_path\": \"bigscience/bloomz-7b1\",\n",
       "  \"apply_residual_connection_post_layernorm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BloomForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"attention_softmax_in_fp32\": true,\n",
       "  \"bias_dropout_fusion\": true,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"masked_softmax_fusion\": true,\n",
       "  \"model_type\": \"bloom\",\n",
       "  \"n_head\": 32,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 30,\n",
       "  \"offset_alibi\": 100,\n",
       "  \"pad_token_id\": 3,\n",
       "  \"pretraining_tp\": 4,\n",
       "  \"seq_length\": 2048,\n",
       "  \"skip_bias_add\": true,\n",
       "  \"skip_bias_add_qkv\": false,\n",
       "  \"slow_but_exact\": false,\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"unk_token_id\": 0,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250880\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b6cdd8d-9434-40fb-b4dc-21c3759ffd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "config._name_or_path=model_name\n",
    "config.hidden_size=4096\n",
    "config.num_hidden_layers=30\n",
    "config.n_head=32\n",
    "config.num_labels=2\n",
    "config.pad_token_id=tokenizer.pad_token_id\n",
    "config.hidden_dropout = 0.1\n",
    "config.transform=False\n",
    "config.text='Classify the textual equivalence from the text:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f8a22cb-3941-4080-aa1e-f7b2983516d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PrefixForSequenceClassification were not initialized from the model checkpoint at bigscience/bloomz-7b1 and are newly initialized: ['transformer.h.5.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.15.input_layernorm.bias', 'prompt_encoder.transfromer.h.9.post_attention_layernorm.bias', 'transformer.h.26.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.20.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.input_layernorm.weight', 'transformer.h.29.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_h_to_4h.weight', 'transformer.h.18.input_layernorm.weight', 'prompt_encoder.transfromer.h.18.self_attention.dense.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.21.mlp.dense_h_to_4h.bias', 'transformer.h.10.mlp.dense_h_to_4h.weight', 'transformer.h.22.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.23.self_attention.query_key_value.weight', 'transformer.h.3.input_layernorm.bias', 'prompt_encoder.transfromer.h.21.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.8.self_attention.dense.bias', 'prompt_encoder.transfromer.h.3.post_attention_layernorm.bias', 'transformer.h.13.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.11.self_attention.dense.bias', 'transformer.h.4.mlp.dense_4h_to_h.bias', 'transformer.h.0.self_attention.dense.bias', 'transformer.h.1.self_attention.dense.weight', 'transformer.h.19.self_attention.dense.bias', 'prompt_encoder.transfromer.h.17.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.24.self_attention.dense.weight', 'prompt_encoder.transfromer.h.26.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.19.self_attention.dense.weight', 'prompt_encoder.transfromer.h.11.post_attention_layernorm.weight', 'transformer.h.11.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.27.self_attention.dense.weight', 'transformer.h.22.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.17.input_layernorm.weight', 'prompt_encoder.transfromer.h.15.mlp.dense_4h_to_h.weight', 'transformer.h.20.post_attention_layernorm.bias', 'transformer.h.23.self_attention.dense.bias', 'transformer.h.5.mlp.dense_4h_to_h.weight', 'transformer.h.21.post_attention_layernorm.bias', 'transformer.h.25.self_attention.dense.bias', 'transformer.h.5.mlp.dense_h_to_4h.weight', 'transformer.h.25.input_layernorm.bias', 'prompt_encoder.transfromer.h.26.mlp.dense_h_to_4h.bias', 'transformer.h.5.self_attention.query_key_value.bias', 'transformer.h.8.self_attention.dense.bias', 'transformer.h.20.input_layernorm.weight', 'transformer.h.14.self_attention.dense.weight', 'prompt_encoder.transfromer.h.24.input_layernorm.weight', 'transformer.h.1.input_layernorm.bias', 'transformer.h.12.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.12.post_attention_layernorm.weight', 'transformer.h.13.input_layernorm.weight', 'prompt_encoder.transfromer.h.14.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.19.input_layernorm.bias', 'transformer.h.2.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.8.input_layernorm.weight', 'prompt_encoder.transfromer.h.6.input_layernorm.bias', 'transformer.h.0.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.input_layernorm.bias', 'prompt_encoder.transfromer.h.0.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.11.input_layernorm.bias', 'prompt_encoder.transfromer.h.25.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.16.self_attention.query_key_value.weight', 'transformer.h.23.mlp.dense_h_to_4h.bias', 'transformer.h.2.post_attention_layernorm.bias', 'transformer.h.14.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.9.input_layernorm.weight', 'prompt_encoder.transfromer.h.25.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.24.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.6.post_attention_layernorm.bias', 'transformer.h.14.mlp.dense_4h_to_h.weight', 'transformer.h.22.self_attention.query_key_value.bias', 'transformer.h.21.self_attention.dense.weight', 'prompt_encoder.transfromer.h.7.mlp.dense_4h_to_h.weight', 'transformer.h.20.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.2.self_attention.query_key_value.weight', 'transformer.h.10.input_layernorm.bias', 'transformer.h.0.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.self_attention.query_key_value.bias', 'transformer.h.14.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.3.mlp.dense_h_to_4h.weight', 'transformer.h.17.input_layernorm.bias', 'transformer.h.23.self_attention.query_key_value.weight', 'transformer.h.17.post_attention_layernorm.weight', 'transformer.h.23.self_attention.dense.weight', 'transformer.h.3.input_layernorm.weight', 'transformer.h.3.mlp.dense_h_to_4h.bias', 'transformer.h.5.input_layernorm.weight', 'transformer.h.0.mlp.dense_h_to_4h.weight', 'transformer.h.7.post_attention_layernorm.weight', 'transformer.h.9.input_layernorm.weight', 'prompt_encoder.transfromer.h.14.input_layernorm.weight', 'transformer.h.5.self_attention.dense.weight', 'transformer.h.8.input_layernorm.weight', 'transformer.h.11.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.15.self_attention.dense.bias', 'prompt_encoder.transfromer.h.10.post_attention_layernorm.bias', 'transformer.h.11.input_layernorm.weight', 'transformer.h.26.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_h_to_4h.bias', 'transformer.h.9.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.6.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.15.self_attention.dense.weight', 'prompt_encoder.transfromer.h.21.post_attention_layernorm.weight', 'transformer.h.5.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.12.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.27.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.13.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.28.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.mlp.dense_4h_to_h.weight', 'transformer.h.25.self_attention.query_key_value.bias', 'transformer.h.27.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.6.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.post_attention_layernorm.bias', 'prompt_encoder.transfromer.ln_f.weight', 'transformer.h.8.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.25.mlp.dense_4h_to_h.bias', 'transformer.h.2.self_attention.dense.bias', 'prompt_encoder.transfromer.h.19.self_attention.query_key_value.weight', 'transformer.h.23.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.17.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.mlp.dense_4h_to_h.weight', 'transformer.h.15.self_attention.dense.bias', 'transformer.h.12.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.0.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.self_attention.dense.bias', 'transformer.h.17.mlp.dense_4h_to_h.weight', 'transformer.h.5.self_attention.query_key_value.weight', 'transformer.h.22.input_layernorm.bias', 'prompt_encoder.transfromer.h.2.mlp.dense_h_to_4h.bias', 'transformer.h.1.self_attention.query_key_value.bias', 'transformer.h.28.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.7.mlp.dense_h_to_4h.weight', 'transformer.h.1.self_attention.dense.bias', 'prompt_encoder.transfromer.h.4.self_attention.dense.bias', 'transformer.h.25.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.21.mlp.dense_h_to_4h.weight', 'transformer.h.11.input_layernorm.bias', 'prompt_encoder.transfromer.h.20.self_attention.dense.weight', 'prompt_encoder.transfromer.h.26.self_attention.query_key_value.bias', 'transformer.h.29.self_attention.query_key_value.weight', 'transformer.h.15.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.12.input_layernorm.weight', 'prompt_encoder.transfromer.h.9.self_attention.dense.bias', 'transformer.h.20.self_attention.query_key_value.weight', 'transformer.h.6.mlp.dense_4h_to_h.weight', 'transformer.h.20.input_layernorm.bias', 'prompt_encoder.transfromer.h.6.self_attention.dense.weight', 'transformer.h.22.self_attention.dense.bias', 'prompt_encoder.transfromer.h.13.post_attention_layernorm.weight', 'transformer.h.24.input_layernorm.bias', 'prompt_encoder.transfromer.h.7.self_attention.dense.bias', 'prompt_encoder.transfromer.h.21.self_attention.dense.weight', 'prompt_encoder.transfromer.h.27.mlp.dense_4h_to_h.weight', 'transformer.h.24.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.8.self_attention.dense.weight', 'prompt_encoder.transfromer.h.20.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.13.mlp.dense_4h_to_h.bias', 'transformer.h.12.input_layernorm.bias', 'prompt_encoder.transfromer.h.19.mlp.dense_h_to_4h.weight', 'transformer.h.16.input_layernorm.weight', 'transformer.h.4.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.20.mlp.dense_h_to_4h.weight', 'transformer.h.15.post_attention_layernorm.weight', 'transformer.h.5.input_layernorm.bias', 'prompt_encoder.transfromer.h.26.input_layernorm.weight', 'transformer.h.6.input_layernorm.bias', 'transformer.h.11.self_attention.query_key_value.weight', 'transformer.h.23.mlp.dense_4h_to_h.weight', 'score.bias', 'prompt_encoder.transfromer.h.20.input_layernorm.bias', 'prompt_encoder.transfromer.h.1.self_attention.query_key_value.weight', 'transformer.h.11.post_attention_layernorm.weight', 'transformer.h.2.mlp.dense_4h_to_h.weight', 'transformer.h.25.self_attention.query_key_value.weight', 'transformer.h.29.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.24.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.29.self_attention.dense.weight', 'transformer.h.28.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.22.input_layernorm.weight', 'transformer.h.6.input_layernorm.weight', 'prompt_encoder.transfromer.h.22.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.29.input_layernorm.weight', 'transformer.h.19.self_attention.query_key_value.weight', 'transformer.h.27.mlp.dense_4h_to_h.weight', 'transformer.h.18.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.9.input_layernorm.bias', 'prompt_encoder.transfromer.h.24.mlp.dense_h_to_4h.weight', 'transformer.h.6.self_attention.query_key_value.weight', 'transformer.h.6.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.post_attention_layernorm.weight', 'transformer.h.14.input_layernorm.bias', 'transformer.h.18.mlp.dense_h_to_4h.bias', 'transformer.h.1.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.16.self_attention.dense.weight', 'prompt_encoder.transfromer.h.22.input_layernorm.bias', 'transformer.h.27.mlp.dense_h_to_4h.bias', 'transformer.h.7.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.13.self_attention.query_key_value.bias', 'transformer.h.15.input_layernorm.weight', 'transformer.h.25.mlp.dense_4h_to_h.bias', 'transformer.h.18.input_layernorm.bias', 'transformer.h.26.self_attention.dense.bias', 'prompt_encoder.transfromer.h.1.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.22.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.2.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.29.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.5.self_attention.dense.bias', 'prompt_encoder.transfromer.h.22.mlp.dense_h_to_4h.bias', 'transformer.h.10.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.5.post_attention_layernorm.weight', 'transformer.h.29.self_attention.query_key_value.bias', 'transformer.h.24.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.12.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.29.self_attention.dense.bias', 'transformer.h.4.input_layernorm.weight', 'prompt_encoder.transfromer.h.2.input_layernorm.bias', 'transformer.h.0.post_attention_layernorm.weight', 'transformer.h.4.self_attention.dense.bias', 'transformer.h.19.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.13.self_attention.dense.weight', 'prompt_encoder.transfromer.h.23.mlp.dense_4h_to_h.bias', 'transformer.h.18.self_attention.dense.weight', 'prompt_encoder.transfromer.h.9.mlp.dense_4h_to_h.weight', 'transformer.h.27.post_attention_layernorm.bias', 'transformer.h.2.self_attention.dense.weight', 'transformer.h.5.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.8.self_attention.query_key_value.weight', 'transformer.h.7.mlp.dense_4h_to_h.bias', 'transformer.h.17.mlp.dense_h_to_4h.weight', 'transformer.h.26.input_layernorm.weight', 'prompt_encoder.transfromer.h.10.self_attention.dense.weight', 'prompt_encoder.transfromer.h.17.self_attention.dense.bias', 'transformer.h.22.mlp.dense_h_to_4h.bias', 'transformer.h.13.self_attention.query_key_value.bias', 'transformer.h.27.self_attention.dense.bias', 'prompt_encoder.transfromer.h.24.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.3.mlp.dense_4h_to_h.bias', 'transformer.h.8.self_attention.query_key_value.bias', 'transformer.h.19.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.input_layernorm.weight', 'prompt_encoder.transfromer.h.24.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.5.post_attention_layernorm.bias', 'transformer.h.8.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.27.self_attention.query_key_value.weight', 'transformer.h.12.self_attention.query_key_value.bias', 'transformer.h.8.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.28.input_layernorm.weight', 'prompt_encoder.transfromer.h.29.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.self_attention.query_key_value.bias', 'transformer.h.24.post_attention_layernorm.bias', 'transformer.h.22.input_layernorm.weight', 'prompt_encoder.transfromer.h.26.self_attention.dense.weight', 'transformer.h.26.input_layernorm.bias', 'prompt_encoder.transfromer.h.27.input_layernorm.weight', 'prompt_encoder.transfromer.h.19.self_attention.query_key_value.bias', 'transformer.h.9.self_attention.dense.bias', 'prompt_encoder.transfromer.h.22.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.9.self_attention.query_key_value.bias', 'transformer.h.26.self_attention.dense.weight', 'transformer.h.21.mlp.dense_4h_to_h.bias', 'transformer.h.2.input_layernorm.bias', 'transformer.h.20.mlp.dense_h_to_4h.bias', 'transformer.h.26.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.4.input_layernorm.bias', 'prompt_encoder.transfromer.h.27.mlp.dense_h_to_4h.weight', 'transformer.h.23.post_attention_layernorm.weight', 'transformer.h.26.mlp.dense_4h_to_h.weight', 'transformer.h.28.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.2.self_attention.dense.weight', 'prompt_encoder.transfromer.h.14.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.16.input_layernorm.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_4h_to_h.weight', 'transformer.h.6.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.self_attention.dense.weight', 'transformer.h.9.input_layernorm.bias', 'transformer.h.28.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.0.self_attention.dense.weight', 'prompt_encoder.transfromer.h.16.mlp.dense_h_to_4h.weight', 'transformer.h.16.self_attention.dense.weight', 'prompt_encoder.transfromer.word_embeddings_layernorm.bias', 'prompt_encoder.transfromer.h.21.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.28.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.20.self_attention.query_key_value.bias', 'transformer.h.18.mlp.dense_4h_to_h.bias', 'transformer.h.17.self_attention.dense.weight', 'prompt_encoder.transfromer.h.26.self_attention.query_key_value.weight', 'transformer.h.17.post_attention_layernorm.bias', 'transformer.h.21.self_attention.dense.bias', 'transformer.h.2.self_attention.query_key_value.bias', 'transformer.h.10.post_attention_layernorm.weight', 'transformer.h.19.post_attention_layernorm.weight', 'transformer.h.29.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_h_to_4h.bias', 'transformer.h.28.post_attention_layernorm.weight', 'transformer.h.7.self_attention.dense.weight', 'transformer.h.10.self_attention.dense.bias', 'prompt_encoder.transfromer.h.11.mlp.dense_h_to_4h.bias', 'transformer.h.17.input_layernorm.weight', 'transformer.h.25.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.11.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.10.input_layernorm.weight', 'prompt_encoder.transfromer.h.3.self_attention.dense.weight', 'transformer.h.16.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.self_attention.dense.bias', 'transformer.h.6.self_attention.dense.bias', 'prompt_encoder.transfromer.h.23.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.3.post_attention_layernorm.weight', 'transformer.h.28.post_attention_layernorm.bias', 'transformer.h.16.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.16.post_attention_layernorm.weight', 'transformer.h.15.mlp.dense_4h_to_h.weight', 'transformer.h.6.self_attention.query_key_value.bias', 'transformer.h.14.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.18.self_attention.query_key_value.weight', 'transformer.h.4.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.3.mlp.dense_h_to_4h.bias', 'transformer.h.13.self_attention.dense.bias', 'prompt_encoder.transfromer.h.6.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.11.self_attention.dense.weight', 'prompt_encoder.transfromer.h.26.self_attention.dense.bias', 'transformer.h.20.self_attention.dense.bias', 'transformer.h.15.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.8.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.23.self_attention.dense.weight', 'transformer.h.13.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.4.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.23.input_layernorm.bias', 'prompt_encoder.transfromer.h.4.input_layernorm.weight', 'prompt_encoder.transfromer.h.27.self_attention.query_key_value.bias', 'transformer.h.3.self_attention.dense.weight', 'transformer.h.24.self_attention.dense.bias', 'prompt_encoder.transfromer.h.15.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.28.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.13.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_4h_to_h.bias', 'transformer.h.8.post_attention_layernorm.weight', 'transformer.h.4.input_layernorm.bias', 'transformer.h.11.post_attention_layernorm.bias', 'transformer.h.21.self_attention.query_key_value.weight', 'transformer.h.14.self_attention.dense.bias', 'transformer.h.23.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.17.input_layernorm.bias', 'transformer.h.10.mlp.dense_h_to_4h.bias', 'transformer.h.3.mlp.dense_4h_to_h.weight', 'transformer.h.14.post_attention_layernorm.weight', 'transformer.h.7.self_attention.query_key_value.weight', 'transformer.h.16.input_layernorm.bias', 'prompt_encoder.transfromer.h.9.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.12.self_attention.dense.weight', 'transformer.h.19.mlp.dense_4h_to_h.bias', 'transformer.h.26.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.18.input_layernorm.bias', 'transformer.h.9.post_attention_layernorm.weight', 'transformer.h.17.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.3.mlp.dense_4h_to_h.weight', 'transformer.h.28.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.7.mlp.dense_4h_to_h.bias', 'transformer.h.27.input_layernorm.weight', 'prompt_encoder.transfromer.h.17.mlp.dense_4h_to_h.weight', 'transformer.h.24.self_attention.query_key_value.weight', 'transformer.h.15.self_attention.dense.weight', 'prompt_encoder.transfromer.h.4.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.13.self_attention.query_key_value.weight', 'transformer.h.16.self_attention.query_key_value.bias', 'transformer.h.9.self_attention.dense.weight', 'prompt_encoder.transfromer.h.10.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.21.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.self_attention.dense.bias', 'transformer.h.12.post_attention_layernorm.bias', 'transformer.h.9.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.8.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.3.input_layernorm.bias', 'transformer.h.28.self_attention.dense.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.19.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_h_to_4h.weight', 'transformer.h.29.self_attention.dense.weight', 'prompt_encoder.transfromer.h.8.mlp.dense_4h_to_h.weight', 'transformer.h.19.self_attention.dense.weight', 'prompt_encoder.transfromer.h.25.self_attention.query_key_value.weight', 'transformer.h.7.self_attention.query_key_value.bias', 'transformer.h.14.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.26.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_4h_to_h.weight', 'transformer.h.9.self_attention.query_key_value.weight', 'transformer.h.11.self_attention.dense.weight', 'prompt_encoder.transfromer.h.5.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.mlp.dense_h_to_4h.bias', 'transformer.h.27.post_attention_layernorm.weight', 'transformer.h.6.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.28.mlp.dense_h_to_4h.bias', 'transformer.h.2.input_layernorm.weight', 'prompt_encoder.transfromer.h.22.post_attention_layernorm.weight', 'transformer.h.20.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.18.mlp.dense_h_to_4h.weight', 'transformer.h.10.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.14.self_attention.query_key_value.bias', 'transformer.h.26.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.17.post_attention_layernorm.weight', 'transformer.h.2.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.9.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.input_layernorm.bias', 'transformer.h.3.mlp.dense_h_to_4h.weight', 'transformer.h.11.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.10.post_attention_layernorm.weight', 'transformer.h.20.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.26.input_layernorm.bias', 'transformer.h.20.self_attention.dense.weight', 'prompt_encoder.transfromer.h.7.self_attention.query_key_value.weight', 'transformer.h.27.self_attention.dense.weight', 'transformer.h.7.input_layernorm.bias', 'prompt_encoder.transfromer.h.3.self_attention.dense.bias', 'prompt_encoder.transfromer.h.8.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.25.self_attention.dense.bias', 'transformer.h.28.self_attention.dense.weight', 'transformer.h.29.self_attention.dense.bias', 'prompt_encoder.transfromer.h.12.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.5.self_attention.dense.weight', 'transformer.h.14.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.28.self_attention.dense.weight', 'prompt_encoder.transfromer.h.4.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_4h_to_h.bias', 'transformer.h.27.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.12.self_attention.query_key_value.bias', 'transformer.h.1.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.6.post_attention_layernorm.weight', 'transformer.h.16.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.8.input_layernorm.bias', 'transformer.h.5.self_attention.dense.bias', 'transformer.h.2.mlp.dense_h_to_4h.weight', 'transformer.h.13.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.5.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.28.mlp.dense_4h_to_h.weight', 'transformer.h.11.mlp.dense_4h_to_h.bias', 'transformer.h.1.input_layernorm.weight', 'transformer.h.15.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.13.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.3.input_layernorm.weight', 'prompt_encoder.transfromer.h.3.self_attention.query_key_value.weight', 'transformer.h.19.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.14.input_layernorm.bias', 'transformer.h.0.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.15.mlp.dense_h_to_4h.bias', 'transformer.h.0.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.14.self_attention.dense.bias', 'prompt_encoder.transfromer.h.15.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.self_attention.query_key_value.bias', 'transformer.h.29.post_attention_layernorm.weight', 'transformer.h.8.self_attention.query_key_value.weight', 'transformer.h.12.post_attention_layernorm.weight', 'transformer.h.3.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.18.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.7.self_attention.dense.weight', 'prompt_encoder.transfromer.h.21.input_layernorm.weight', 'transformer.h.19.input_layernorm.weight', 'transformer.h.6.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.25.input_layernorm.bias', 'prompt_encoder.transfromer.h.14.self_attention.dense.weight', 'transformer.h.22.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.4.self_attention.query_key_value.bias', 'transformer.h.6.self_attention.dense.weight', 'score.weight', 'transformer.word_embeddings.weight', 'prompt_encoder.transfromer.h.5.mlp.dense_4h_to_h.weight', 'transformer.word_embeddings_layernorm.bias', 'transformer.h.15.input_layernorm.bias', 'prompt_encoder.transfromer.h.7.input_layernorm.weight', 'prompt_encoder.transfromer.h.27.mlp.dense_4h_to_h.bias', 'transformer.h.17.self_attention.query_key_value.bias', 'transformer.h.10.mlp.dense_4h_to_h.bias', 'transformer.h.10.input_layernorm.weight', 'transformer.h.19.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.15.post_attention_layernorm.bias', 'transformer.h.21.post_attention_layernorm.weight', 'transformer.h.20.post_attention_layernorm.weight', 'transformer.h.23.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.6.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.10.self_attention.dense.bias', 'prompt_encoder.transfromer.h.23.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.input_layernorm.bias', 'prompt_encoder.transfromer.h.1.self_attention.dense.bias', 'prompt_encoder.transfromer.h.26.mlp.dense_4h_to_h.bias', 'transformer.h.23.self_attention.query_key_value.bias', 'transformer.h.28.input_layernorm.weight', 'transformer.h.18.self_attention.dense.bias', 'prompt_encoder.transfromer.h.8.mlp.dense_h_to_4h.bias', 'transformer.h.29.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.4.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_h_to_4h.weight', 'transformer.h.12.self_attention.dense.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_4h_to_h.weight', 'transformer.h.5.post_attention_layernorm.weight', 'transformer.h.26.self_attention.query_key_value.weight', 'transformer.h.1.self_attention.query_key_value.weight', 'transformer.h.17.self_attention.dense.bias', 'prompt_encoder.transfromer.h.11.post_attention_layernorm.bias', 'transformer.h.20.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.6.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.11.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.self_attention.dense.bias', 'prompt_encoder.transfromer.h.20.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.16.self_attention.dense.bias', 'transformer.h.25.self_attention.dense.weight', 'transformer.h.8.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.28.post_attention_layernorm.weight', 'transformer.h.10.self_attention.dense.weight', 'transformer.h.7.mlp.dense_4h_to_h.weight', 'transformer.h.25.mlp.dense_h_to_4h.bias', 'transformer.h.12.mlp.dense_4h_to_h.bias', 'transformer.h.16.self_attention.query_key_value.weight', 'transformer.h.21.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.23.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.5.mlp.dense_4h_to_h.bias', 'transformer.h.16.self_attention.dense.bias', 'transformer.h.4.self_attention.query_key_value.weight', 'transformer.h.17.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.1.self_attention.dense.weight', 'transformer.h.18.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.21.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.4.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.9.post_attention_layernorm.weight', 'transformer.h.7.self_attention.dense.bias', 'prompt_encoder.transfromer.h.26.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.24.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.15.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.word_embeddings_layernorm.weight', 'prompt_encoder.transfromer.h.18.self_attention.dense.weight', 'transformer.h.26.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.10.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.28.post_attention_layernorm.bias', 'transformer.h.21.mlp.dense_h_to_4h.weight', 'transformer.h.24.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.19.post_attention_layernorm.bias', 'prompt_encoder.transfromer.ln_f.bias', 'prompt_encoder.transfromer.h.6.self_attention.dense.bias', 'prompt_encoder.transfromer.h.29.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.4.mlp.dense_h_to_4h.weight', 'transformer.h.16.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.22.self_attention.dense.weight', 'transformer.h.1.post_attention_layernorm.bias', 'transformer.h.21.input_layernorm.bias', 'prompt_encoder.transfromer.h.22.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.17.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.27.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.5.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.5.input_layernorm.bias', 'transformer.h.0.input_layernorm.bias', 'transformer.h.13.mlp.dense_h_to_4h.weight', 'transformer.h.19.mlp.dense_h_to_4h.bias', 'transformer.h.24.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.0.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.input_layernorm.weight', 'prompt_encoder.transfromer.h.11.mlp.dense_h_to_4h.weight', 'transformer.ln_f.weight', 'transformer.h.19.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.0.post_attention_layernorm.bias', 'transformer.h.8.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.28.self_attention.dense.bias', 'transformer.h.6.post_attention_layernorm.bias', 'transformer.h.7.input_layernorm.weight', 'prompt_encoder.transfromer.h.25.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.5.mlp.dense_h_to_4h.bias', 'transformer.word_embeddings_layernorm.weight', 'transformer.h.21.input_layernorm.weight', 'prompt_encoder.transfromer.h.18.mlp.dense_h_to_4h.bias', 'prompt_encoder.embedding.weight', 'transformer.h.17.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.2.mlp.dense_4h_to_h.bias', 'transformer.h.24.self_attention.dense.weight', 'transformer.h.4.post_attention_layernorm.weight', 'transformer.h.0.mlp.dense_4h_to_h.bias', 'transformer.h.16.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.28.input_layernorm.bias', 'prompt_encoder.transfromer.h.11.mlp.dense_4h_to_h.weight', 'transformer.h.25.post_attention_layernorm.bias', 'transformer.h.1.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.14.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.mlp.dense_4h_to_h.weight', 'transformer.h.2.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.8.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.29.input_layernorm.bias', 'transformer.h.12.mlp.dense_h_to_4h.bias', 'transformer.h.0.input_layernorm.weight', 'transformer.h.23.input_layernorm.bias', 'transformer.h.28.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.11.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.word_embeddings.weight', 'prompt_encoder.transfromer.h.29.post_attention_layernorm.weight', 'transformer.h.25.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.7.input_layernorm.bias', 'transformer.h.13.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.self_attention.query_key_value.bias', 'transformer.h.12.self_attention.dense.bias', 'transformer.h.13.mlp.dense_4h_to_h.bias', 'transformer.h.21.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.16.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.6.input_layernorm.weight', 'prompt_encoder.transfromer.h.16.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.16.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.17.mlp.dense_h_to_4h.weight', 'transformer.h.18.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.22.self_attention.query_key_value.bias', 'transformer.h.18.post_attention_layernorm.bias', 'transformer.h.9.mlp.dense_4h_to_h.bias', 'transformer.h.18.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.25.input_layernorm.weight', 'prompt_encoder.transfromer.h.26.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_4h_to_h.weight', 'transformer.h.24.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.18.self_attention.query_key_value.bias', 'transformer.h.1.mlp.dense_h_to_4h.weight', 'transformer.h.14.input_layernorm.weight', 'prompt_encoder.transfromer.h.7.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.post_attention_layernorm.bias', 'transformer.h.13.input_layernorm.bias', 'transformer.h.8.mlp.dense_h_to_4h.bias', 'transformer.h.1.mlp.dense_4h_to_h.weight', 'transformer.h.27.input_layernorm.bias', 'prompt_encoder.transfromer.h.15.post_attention_layernorm.weight', 'transformer.h.18.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.0.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.10.input_layernorm.bias', 'transformer.h.3.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.9.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.post_attention_layernorm.bias', 'transformer.h.4.self_attention.dense.weight', 'transformer.h.15.mlp.dense_4h_to_h.bias', 'transformer.h.3.self_attention.dense.bias', 'transformer.h.29.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.8.mlp.dense_h_to_4h.weight', 'transformer.h.16.mlp.dense_4h_to_h.bias', 'transformer.h.28.input_layernorm.bias', 'prompt_encoder.transfromer.h.12.self_attention.dense.bias', 'transformer.h.3.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.9.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.25.self_attention.query_key_value.bias', 'transformer.h.23.input_layernorm.weight', 'transformer.h.9.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.22.post_attention_layernorm.bias', 'transformer.h.10.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.23.self_attention.dense.bias', 'prompt_encoder.transfromer.h.17.self_attention.dense.weight', 'prompt_encoder.transfromer.h.16.input_layernorm.bias', 'transformer.h.22.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.16.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.post_attention_layernorm.bias', 'transformer.h.27.mlp.dense_h_to_4h.weight', 'transformer.h.29.input_layernorm.weight', 'transformer.h.0.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.1.post_attention_layernorm.bias', 'transformer.h.4.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.18.mlp.dense_4h_to_h.bias', 'transformer.h.22.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.15.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_h_to_4h.weight', 'transformer.h.13.mlp.dense_h_to_4h.bias', 'transformer.h.15.mlp.dense_h_to_4h.bias', 'transformer.h.14.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.13.self_attention.dense.bias', 'transformer.h.24.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.15.mlp.dense_h_to_4h.weight', 'transformer.ln_f.bias', 'transformer.h.3.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.12.post_attention_layernorm.bias', 'transformer.h.22.self_attention.dense.weight', 'prompt_encoder.transfromer.h.21.input_layernorm.bias', 'prompt_encoder.transfromer.h.17.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.11.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.17.post_attention_layernorm.bias', 'transformer.h.8.self_attention.dense.weight', 'transformer.h.27.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.20.input_layernorm.weight', 'prompt_encoder.transfromer.h.4.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.28.mlp.dense_4h_to_h.bias', 'transformer.h.24.input_layernorm.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_4h_to_h.bias', 'transformer.h.11.self_attention.dense.bias', 'prompt_encoder.transfromer.h.24.self_attention.dense.bias', 'transformer.h.15.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.27.self_attention.dense.bias', 'transformer.h.4.mlp.dense_h_to_4h.bias', 'transformer.h.9.mlp.dense_4h_to_h.weight', 'transformer.h.2.post_attention_layernorm.weight', 'transformer.h.25.input_layernorm.weight', 'transformer.h.7.post_attention_layernorm.bias', 'transformer.h.10.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.input_layernorm.weight', 'transformer.h.0.self_attention.dense.weight', 'transformer.h.12.input_layernorm.weight', 'transformer.h.21.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.20.self_attention.query_key_value.weight', 'transformer.h.22.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.20.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.21.mlp.dense_4h_to_h.bias', 'transformer.h.12.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.22.self_attention.dense.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.27.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.24.input_layernorm.bias', 'transformer.h.11.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.5.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.input_layernorm.weight', 'transformer.h.3.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.16.mlp.dense_4h_to_h.bias', 'transformer.h.7.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.9.mlp.dense_h_to_4h.weight', 'transformer.h.4.mlp.dense_4h_to_h.weight', 'transformer.h.29.input_layernorm.bias', 'transformer.h.13.self_attention.dense.weight', 'prompt_encoder.transfromer.h.21.self_attention.dense.bias', 'prompt_encoder.transfromer.h.27.input_layernorm.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.3.self_attention.query_key_value.bias', 'transformer.h.9.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.6.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.4.mlp.dense_4h_to_h.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix sequence length 8\n"
     ]
    }
   ],
   "source": [
    "from bloomSKT import  PrefixForSequenceClassification\n",
    "\n",
    "model = PrefixForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbd31bc-596b-4012-8925-be431b9fe680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 7069057026\n",
      "Trainable Parameters: 40962\n",
      "Percentage Trainable: 0.00057945493789824743%\n"
     ]
    }
   ],
   "source": [
    "# Total number of parameters in the model\n",
    "total_parameters = model.num_parameters()\n",
    "\n",
    "# Total number of trainable parameters in the model\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Calculate the percentage of trainable parameters\n",
    "percentage_trainable = (trainable_parameters / total_parameters) * 100\n",
    "\n",
    "print(f\"Total Parameters: {total_parameters}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters}\")\n",
    "print(f\"Percentage Trainable: {percentage_trainable:.20f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171405eb-cba9-4ae0-a2bd-7e85df4adae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47afa401-33fc-4d55-bddc-e9e42d4a0607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6801' max='9180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6801/9180 2:37:29 < 55:06, 0.72 it/s, Epoch 14.81/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.662200</td>\n",
       "      <td>0.618242</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.572685</td>\n",
       "      <td>0.563513</td>\n",
       "      <td>0.703431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>0.576853</td>\n",
       "      <td>0.707318</td>\n",
       "      <td>0.603109</td>\n",
       "      <td>0.602817</td>\n",
       "      <td>0.727941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.529487</td>\n",
       "      <td>0.776679</td>\n",
       "      <td>0.646953</td>\n",
       "      <td>0.658353</td>\n",
       "      <td>0.762255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>0.487415</td>\n",
       "      <td>0.830595</td>\n",
       "      <td>0.661582</td>\n",
       "      <td>0.676658</td>\n",
       "      <td>0.779412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.430975</td>\n",
       "      <td>0.785033</td>\n",
       "      <td>0.758106</td>\n",
       "      <td>0.768660</td>\n",
       "      <td>0.808824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.414800</td>\n",
       "      <td>0.395787</td>\n",
       "      <td>0.803811</td>\n",
       "      <td>0.775110</td>\n",
       "      <td>0.786456</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.406774</td>\n",
       "      <td>0.849413</td>\n",
       "      <td>0.747437</td>\n",
       "      <td>0.772720</td>\n",
       "      <td>0.828431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.374187</td>\n",
       "      <td>0.840325</td>\n",
       "      <td>0.791239</td>\n",
       "      <td>0.808783</td>\n",
       "      <td>0.845588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>0.346826</td>\n",
       "      <td>0.866257</td>\n",
       "      <td>0.798116</td>\n",
       "      <td>0.820548</td>\n",
       "      <td>0.857843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.364130</td>\n",
       "      <td>0.842738</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.816783</td>\n",
       "      <td>0.850490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>0.352841</td>\n",
       "      <td>0.854418</td>\n",
       "      <td>0.790656</td>\n",
       "      <td>0.811795</td>\n",
       "      <td>0.850490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.380336</td>\n",
       "      <td>0.886433</td>\n",
       "      <td>0.781737</td>\n",
       "      <td>0.810252</td>\n",
       "      <td>0.855392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.340423</td>\n",
       "      <td>0.853478</td>\n",
       "      <td>0.808535</td>\n",
       "      <td>0.825342</td>\n",
       "      <td>0.857843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.347871</td>\n",
       "      <td>0.860195</td>\n",
       "      <td>0.808244</td>\n",
       "      <td>0.826994</td>\n",
       "      <td>0.860294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.367907</td>\n",
       "      <td>0.856499</td>\n",
       "      <td>0.794532</td>\n",
       "      <td>0.815396</td>\n",
       "      <td>0.852941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.347295</td>\n",
       "      <td>0.862095</td>\n",
       "      <td>0.818080</td>\n",
       "      <td>0.834804</td>\n",
       "      <td>0.865196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.344196</td>\n",
       "      <td>0.846670</td>\n",
       "      <td>0.822831</td>\n",
       "      <td>0.832978</td>\n",
       "      <td>0.860294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.343447</td>\n",
       "      <td>0.845407</td>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.865196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.359604</td>\n",
       "      <td>0.862111</td>\n",
       "      <td>0.824039</td>\n",
       "      <td>0.839041</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.340229</td>\n",
       "      <td>0.854514</td>\n",
       "      <td>0.840418</td>\n",
       "      <td>0.846837</td>\n",
       "      <td>0.870098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.853586</td>\n",
       "      <td>0.814495</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.860294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.290798</td>\n",
       "      <td>0.874966</td>\n",
       "      <td>0.847295</td>\n",
       "      <td>0.860015</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.309738</td>\n",
       "      <td>0.870915</td>\n",
       "      <td>0.821664</td>\n",
       "      <td>0.839982</td>\n",
       "      <td>0.870098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.327589</td>\n",
       "      <td>0.876852</td>\n",
       "      <td>0.839251</td>\n",
       "      <td>0.854310</td>\n",
       "      <td>0.879902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.355457</td>\n",
       "      <td>0.881113</td>\n",
       "      <td>0.841044</td>\n",
       "      <td>0.856926</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.364872</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.849046</td>\n",
       "      <td>0.847593</td>\n",
       "      <td>0.867647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.226900</td>\n",
       "      <td>0.379748</td>\n",
       "      <td>0.877039</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>0.850207</td>\n",
       "      <td>0.877451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.378827</td>\n",
       "      <td>0.876852</td>\n",
       "      <td>0.839251</td>\n",
       "      <td>0.854310</td>\n",
       "      <td>0.879902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.448393</td>\n",
       "      <td>0.877983</td>\n",
       "      <td>0.795741</td>\n",
       "      <td>0.821084</td>\n",
       "      <td>0.860294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>0.386783</td>\n",
       "      <td>0.883987</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.852059</td>\n",
       "      <td>0.879902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.388586</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.833875</td>\n",
       "      <td>0.846528</td>\n",
       "      <td>0.872549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.395020</td>\n",
       "      <td>0.866405</td>\n",
       "      <td>0.831791</td>\n",
       "      <td>0.845774</td>\n",
       "      <td>0.872549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.868548</td>\n",
       "      <td>0.835667</td>\n",
       "      <td>0.849111</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.409315</td>\n",
       "      <td>0.881452</td>\n",
       "      <td>0.835084</td>\n",
       "      <td>0.852826</td>\n",
       "      <td>0.879902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removed shared tensor {'prompt_encoder.transfromer.h.15.input_layernorm.bias', 'prompt_encoder.transfromer.h.9.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.20.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.input_layernorm.weight', 'prompt_encoder.transfromer.h.29.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.18.self_attention.dense.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.21.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.21.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.8.self_attention.dense.bias', 'prompt_encoder.transfromer.h.3.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.11.self_attention.dense.bias', 'prompt_encoder.transfromer.h.17.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.24.self_attention.dense.weight', 'prompt_encoder.transfromer.h.26.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.19.self_attention.dense.weight', 'prompt_encoder.transfromer.h.11.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.27.self_attention.dense.weight', 'prompt_encoder.transfromer.h.17.input_layernorm.weight', 'prompt_encoder.transfromer.h.15.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.26.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.24.input_layernorm.weight', 'prompt_encoder.transfromer.h.12.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.19.input_layernorm.bias', 'prompt_encoder.transfromer.h.8.input_layernorm.weight', 'prompt_encoder.transfromer.h.6.input_layernorm.bias', 'prompt_encoder.transfromer.h.1.input_layernorm.bias', 'prompt_encoder.transfromer.h.0.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.11.input_layernorm.bias', 'prompt_encoder.transfromer.h.25.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.16.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.9.input_layernorm.weight', 'prompt_encoder.transfromer.h.25.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.24.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.6.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.7.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.23.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.3.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.14.input_layernorm.weight', 'prompt_encoder.transfromer.h.15.self_attention.dense.bias', 'prompt_encoder.transfromer.h.10.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.0.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.21.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.6.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.15.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.27.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.13.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.28.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.6.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.post_attention_layernorm.bias', 'prompt_encoder.transfromer.ln_f.weight', 'prompt_encoder.transfromer.h.13.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.25.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.19.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.17.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.18.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.0.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.self_attention.dense.bias', 'prompt_encoder.transfromer.h.2.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.7.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.4.self_attention.dense.bias', 'prompt_encoder.transfromer.h.21.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.26.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.20.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.input_layernorm.weight', 'prompt_encoder.transfromer.h.9.self_attention.dense.bias', 'prompt_encoder.transfromer.h.6.self_attention.dense.weight', 'prompt_encoder.transfromer.h.13.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.27.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.self_attention.dense.bias', 'prompt_encoder.transfromer.h.21.self_attention.dense.weight', 'prompt_encoder.transfromer.h.8.self_attention.dense.weight', 'prompt_encoder.transfromer.h.20.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.13.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.19.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.20.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.26.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.input_layernorm.bias', 'prompt_encoder.transfromer.h.1.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.29.self_attention.dense.weight', 'prompt_encoder.transfromer.h.22.input_layernorm.weight', 'prompt_encoder.transfromer.h.22.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.29.input_layernorm.weight', 'prompt_encoder.transfromer.h.9.input_layernorm.bias', 'prompt_encoder.transfromer.h.24.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.23.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.16.self_attention.dense.weight', 'prompt_encoder.transfromer.h.22.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.1.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.22.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.25.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.29.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.2.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.5.self_attention.dense.bias', 'prompt_encoder.transfromer.h.22.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.0.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.5.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.29.self_attention.dense.bias', 'prompt_encoder.transfromer.h.12.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.2.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.self_attention.dense.weight', 'prompt_encoder.transfromer.h.23.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.9.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.8.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.10.self_attention.dense.weight', 'prompt_encoder.transfromer.h.17.self_attention.dense.bias', 'prompt_encoder.transfromer.h.24.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.3.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.13.input_layernorm.weight', 'prompt_encoder.transfromer.h.24.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.5.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.27.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.1.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.28.input_layernorm.weight', 'prompt_encoder.transfromer.h.29.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.26.self_attention.dense.weight', 'prompt_encoder.transfromer.h.27.input_layernorm.weight', 'prompt_encoder.transfromer.h.19.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.22.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.9.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.4.input_layernorm.bias', 'prompt_encoder.transfromer.h.27.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.16.input_layernorm.weight', 'prompt_encoder.transfromer.h.2.self_attention.dense.weight', 'prompt_encoder.transfromer.h.14.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.25.self_attention.dense.weight', 'prompt_encoder.transfromer.h.0.self_attention.dense.weight', 'prompt_encoder.transfromer.h.16.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.word_embeddings_layernorm.bias', 'prompt_encoder.transfromer.h.21.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.28.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.20.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.26.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.11.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.11.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.10.input_layernorm.weight', 'prompt_encoder.transfromer.h.3.self_attention.dense.weight', 'prompt_encoder.transfromer.h.2.self_attention.dense.bias', 'prompt_encoder.transfromer.h.23.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.3.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.16.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.18.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.3.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.11.self_attention.dense.weight', 'prompt_encoder.transfromer.h.6.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.26.self_attention.dense.bias', 'prompt_encoder.transfromer.h.8.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.23.self_attention.dense.weight', 'prompt_encoder.transfromer.h.23.input_layernorm.bias', 'prompt_encoder.transfromer.h.4.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.4.input_layernorm.weight', 'prompt_encoder.transfromer.h.27.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.28.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.15.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.13.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.17.input_layernorm.bias', 'prompt_encoder.transfromer.h.12.self_attention.dense.weight', 'prompt_encoder.transfromer.h.9.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.18.input_layernorm.bias', 'prompt_encoder.transfromer.h.3.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.17.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.4.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.13.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.10.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.21.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.19.self_attention.dense.bias', 'prompt_encoder.transfromer.h.8.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.3.input_layernorm.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.19.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.8.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.25.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.26.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.29.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.5.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.28.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.22.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.18.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.14.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.17.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.9.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.input_layernorm.bias', 'prompt_encoder.transfromer.h.10.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.26.input_layernorm.bias', 'prompt_encoder.transfromer.h.7.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.3.self_attention.dense.bias', 'prompt_encoder.transfromer.h.8.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.25.self_attention.dense.bias', 'prompt_encoder.transfromer.h.12.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.5.self_attention.dense.weight', 'prompt_encoder.transfromer.h.28.self_attention.dense.weight', 'prompt_encoder.transfromer.h.4.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.12.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.6.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.8.input_layernorm.bias', 'prompt_encoder.transfromer.h.5.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.28.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.13.input_layernorm.bias', 'prompt_encoder.transfromer.h.13.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.3.input_layernorm.weight', 'prompt_encoder.transfromer.h.3.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.14.input_layernorm.bias', 'prompt_encoder.transfromer.h.15.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.14.self_attention.dense.bias', 'prompt_encoder.transfromer.h.15.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.18.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.7.self_attention.dense.weight', 'prompt_encoder.transfromer.h.21.input_layernorm.weight', 'prompt_encoder.transfromer.h.25.input_layernorm.bias', 'prompt_encoder.transfromer.h.14.self_attention.dense.weight', 'prompt_encoder.transfromer.h.4.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.5.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.input_layernorm.weight', 'prompt_encoder.transfromer.h.27.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.15.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.6.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.10.self_attention.dense.bias', 'prompt_encoder.transfromer.h.23.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.input_layernorm.bias', 'prompt_encoder.transfromer.h.1.self_attention.dense.bias', 'prompt_encoder.transfromer.h.26.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.8.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.4.self_attention.dense.weight', 'prompt_encoder.transfromer.h.12.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.24.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.11.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.6.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.11.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.self_attention.dense.bias', 'prompt_encoder.transfromer.h.20.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.16.self_attention.dense.bias', 'prompt_encoder.transfromer.h.28.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.23.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.5.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.1.self_attention.dense.weight', 'prompt_encoder.transfromer.h.21.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.4.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.9.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.26.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.24.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.15.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.word_embeddings_layernorm.weight', 'prompt_encoder.transfromer.h.18.self_attention.dense.weight', 'prompt_encoder.transfromer.h.10.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.28.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.19.post_attention_layernorm.bias', 'prompt_encoder.transfromer.ln_f.bias', 'prompt_encoder.transfromer.h.6.self_attention.dense.bias', 'prompt_encoder.transfromer.h.29.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.4.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.22.self_attention.dense.weight', 'prompt_encoder.transfromer.h.22.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.17.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.27.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.5.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.5.input_layernorm.bias', 'prompt_encoder.transfromer.h.18.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.11.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.0.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.28.self_attention.dense.bias', 'prompt_encoder.transfromer.h.25.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.5.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.18.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.28.input_layernorm.bias', 'prompt_encoder.transfromer.h.11.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.14.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.2.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.8.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.29.input_layernorm.bias', 'prompt_encoder.transfromer.h.11.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.29.post_attention_layernorm.weight', 'prompt_encoder.transfromer.word_embeddings.weight', 'prompt_encoder.transfromer.h.7.input_layernorm.bias', 'prompt_encoder.transfromer.h.7.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.16.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.6.input_layernorm.weight', 'prompt_encoder.transfromer.h.16.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.16.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.7.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.17.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.22.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.26.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.25.input_layernorm.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.18.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.7.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.14.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.15.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.0.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.10.input_layernorm.bias', 'prompt_encoder.transfromer.h.9.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.2.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.8.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.12.self_attention.dense.bias', 'prompt_encoder.transfromer.h.9.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.25.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.22.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.23.self_attention.dense.bias', 'prompt_encoder.transfromer.h.17.self_attention.dense.weight', 'prompt_encoder.transfromer.h.16.input_layernorm.bias', 'prompt_encoder.transfromer.h.16.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.23.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.1.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.1.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.18.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.15.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.13.self_attention.dense.bias', 'prompt_encoder.transfromer.h.15.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.12.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.21.input_layernorm.bias', 'prompt_encoder.transfromer.h.17.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.11.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.17.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.20.input_layernorm.weight', 'prompt_encoder.transfromer.h.4.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.28.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.19.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.24.self_attention.dense.bias', 'prompt_encoder.transfromer.h.27.self_attention.dense.bias', 'prompt_encoder.transfromer.h.1.input_layernorm.weight', 'prompt_encoder.transfromer.h.20.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.20.post_attention_layernorm.weight', 'prompt_encoder.transfromer.h.19.mlp.dense_4h_to_h.weight', 'prompt_encoder.transfromer.h.21.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.7.post_attention_layernorm.bias', 'prompt_encoder.transfromer.h.22.self_attention.dense.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.27.mlp.dense_h_to_4h.bias', 'prompt_encoder.transfromer.h.24.input_layernorm.bias', 'prompt_encoder.transfromer.h.2.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.19.input_layernorm.weight', 'prompt_encoder.transfromer.h.5.self_attention.query_key_value.weight', 'prompt_encoder.transfromer.h.16.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.9.mlp.dense_h_to_4h.weight', 'prompt_encoder.transfromer.h.21.self_attention.dense.bias', 'prompt_encoder.transfromer.h.27.input_layernorm.bias', 'prompt_encoder.transfromer.h.10.mlp.dense_4h_to_h.bias', 'prompt_encoder.transfromer.h.3.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.6.self_attention.query_key_value.bias', 'prompt_encoder.transfromer.h.4.mlp.dense_4h_to_h.bias'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./r_task\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#learning_rate=1e-5,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     21\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1914\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1914\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2355\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2354\u001b[0m     staging_output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2355\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstaging_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   2359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(staging_output_dir)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2849\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2849\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2909\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2907\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2909\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2914\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2376\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2372\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_file, shard \u001b[38;5;129;01min\u001b[39;00m shards\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   2374\u001b[0m         \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   2375\u001b[0m         \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 2376\u001b[0m         \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2378\u001b[0m         save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/safetensors/torch.py:281\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    251\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    252\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    253\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    254\u001b[0m ):\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./r_task',\n",
    "    #learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=200,\n",
    "    logging_steps=200,\n",
    "   \n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16762135-f4cc-4626-a4cb-361567e26284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
