{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52654071-04b0-4623-9948-1d249877efcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaae9f51-b77e-4e05-80a0-051b12d6f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = 'sst2' \n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb831da5-9a41-4aee-a132-65e0eff6d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'sentence', 'label'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd1d1a4-aec3-4a69-a129-68553964a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31837a8f-ebe8-4611-86f9-fe3a00510e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39abcbbe42c4d7c987cfb59a3d503d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b864739e6394deba567c2b60ea22c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c461b1563c4f475c885577e4157b7d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "# llama_tokenizer.pad_token_id = llama_tokenizer.eos_token_id\n",
    "# llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "col_to_delete = ['idx']\n",
    "col_to_delete = ['idx', 'sentence']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb88865-8ca4-48be-bfeb-762a624d95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5142e3-0546-4edb-8b8b-c314c4ba3b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralConfig {\n",
       "  \"_name_or_path\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
       "  \"architectures\": [\n",
       "    \"MistralForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"mistral\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b6cdd8d-9434-40fb-b4dc-21c3759ffd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "config._name_or_path=model_name\n",
    "config.hidden_size=4096\n",
    "config.num_hidden_layers=32\n",
    "config.n_head=32\n",
    "config.num_labels=2\n",
    "config.pad_token_id=tokenizer.pad_token_id\n",
    "config.hidden_dropout = 0.1\n",
    "config.transform=False\n",
    "config.text='Classify the positive or negative sentiment from the text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8a22cb-3941-4080-aa1e-f7b2983516d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6fda5bc41d4526abdaa2c2ad9c89d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix sequence length:  11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7dbd0a536a49c1b27ea2f12f152d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PrefixForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.2 and are newly initialized: ['prompt_encoder.transfromer.layers.14.self_attn.v_proj.weight', 'transformer.layers.21.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.24.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.14.input_layernorm.weight', 'prompt_encoder.transfromer.layers.1.post_attention_layernorm.weight', 'transformer.layers.14.mlp.down_proj.weight', 'transformer.layers.7.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.12.mlp.gate_proj.weight', 'transformer.layers.17.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.v_proj.weight', 'transformer.layers.18.post_attention_layernorm.weight', 'transformer.layers.30.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.27.post_attention_layernorm.weight', 'transformer.layers.9.self_attn.o_proj.weight', 'transformer.layers.8.mlp.up_proj.weight', 'transformer.layers.10.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.q_proj.weight', 'transformer.layers.13.input_layernorm.weight', 'prompt_encoder.transfromer.layers.26.mlp.down_proj.weight', 'transformer.layers.28.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.q_proj.weight', 'transformer.layers.18.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.k_proj.weight', 'transformer.layers.28.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.11.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.k_proj.weight', 'transformer.layers.19.self_attn.k_proj.weight', 'transformer.layers.30.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.12.self_attn.o_proj.weight', 'transformer.layers.4.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.17.mlp.down_proj.weight', 'transformer.layers.3.self_attn.v_proj.weight', 'transformer.layers.9.self_attn.q_proj.weight', 'transformer.layers.10.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.20.mlp.up_proj.weight', 'transformer.layers.11.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.18.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.27.self_attn.q_proj.weight', 'transformer.layers.26.mlp.down_proj.weight', 'transformer.layers.4.input_layernorm.weight', 'prompt_encoder.transfromer.layers.24.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.o_proj.weight', 'transformer.layers.1.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.6.post_attention_layernorm.weight', 'transformer.layers.24.mlp.down_proj.weight', 'transformer.layers.19.mlp.up_proj.weight', 'transformer.layers.27.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.18.mlp.up_proj.weight', 'transformer.layers.10.self_attn.k_proj.weight', 'transformer.layers.21.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.3.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.12.input_layernorm.weight', 'prompt_encoder.transfromer.layers.22.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.22.input_layernorm.weight', 'transformer.layers.23.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.8.input_layernorm.weight', 'transformer.layers.5.self_attn.v_proj.weight', 'transformer.layers.0.input_layernorm.weight', 'transformer.layers.19.input_layernorm.weight', 'prompt_encoder.transfromer.layers.2.input_layernorm.weight', 'transformer.layers.29.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.12.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.8.mlp.down_proj.weight', 'transformer.layers.20.post_attention_layernorm.weight', 'transformer.layers.25.post_attention_layernorm.weight', 'prompt_encoder.embedding.weight', 'transformer.layers.1.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.6.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.input_layernorm.weight', 'transformer.layers.9.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.11.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.13.mlp.down_proj.weight', 'transformer.layers.20.self_attn.v_proj.weight', 'transformer.layers.13.self_attn.q_proj.weight', 'transformer.layers.2.mlp.up_proj.weight', 'transformer.layers.29.self_attn.k_proj.weight', 'transformer.layers.7.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.0.mlp.down_proj.weight', 'transformer.layers.3.mlp.up_proj.weight', 'transformer.layers.16.self_attn.v_proj.weight', 'transformer.layers.31.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.0.input_layernorm.weight', 'transformer.layers.5.self_attn.k_proj.weight', 'transformer.layers.25.self_attn.o_proj.weight', 'transformer.layers.28.self_attn.o_proj.weight', 'transformer.layers.25.self_attn.k_proj.weight', 'transformer.layers.4.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.19.self_attn.q_proj.weight', 'transformer.layers.28.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.4.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.29.input_layernorm.weight', 'transformer.layers.31.input_layernorm.weight', 'transformer.layers.16.self_attn.k_proj.weight', 'transformer.layers.28.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.0.mlp.up_proj.weight', 'transformer.layers.11.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.9.input_layernorm.weight', 'transformer.layers.26.mlp.gate_proj.weight', 'transformer.layers.0.mlp.up_proj.weight', 'transformer.layers.14.input_layernorm.weight', 'prompt_encoder.transfromer.layers.16.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.21.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.10.self_attn.o_proj.weight', 'transformer.layers.28.input_layernorm.weight', 'prompt_encoder.transfromer.layers.26.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.26.input_layernorm.weight', 'score.bias', 'transformer.layers.22.self_attn.v_proj.weight', 'transformer.layers.12.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.4.input_layernorm.weight', 'transformer.layers.7.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.19.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.30.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.22.self_attn.q_proj.weight', 'transformer.layers.3.self_attn.o_proj.weight', 'transformer.layers.14.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.o_proj.weight', 'transformer.layers.13.mlp.up_proj.weight', 'transformer.layers.23.mlp.down_proj.weight', 'transformer.layers.9.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.10.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.9.mlp.down_proj.weight', 'transformer.layers.23.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.q_proj.weight', 'transformer.layers.2.input_layernorm.weight', 'prompt_encoder.transfromer.layers.24.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.7.mlp.up_proj.weight', 'transformer.layers.13.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.13.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.4.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.21.input_layernorm.weight', 'prompt_encoder.transfromer.layers.29.self_attn.q_proj.weight', 'transformer.layers.29.input_layernorm.weight', 'prompt_encoder.transfromer.layers.28.post_attention_layernorm.weight', 'transformer.layers.24.self_attn.q_proj.weight', 'transformer.layers.18.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.3.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.mlp.up_proj.weight', 'transformer.layers.27.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.23.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.15.mlp.down_proj.weight', 'transformer.layers.3.input_layernorm.weight', 'transformer.layers.15.input_layernorm.weight', 'transformer.layers.1.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.29.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.o_proj.weight', 'transformer.layers.14.self_attn.k_proj.weight', 'transformer.layers.14.mlp.up_proj.weight', 'transformer.layers.22.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.22.mlp.up_proj.weight', 'transformer.layers.21.input_layernorm.weight', 'prompt_encoder.transfromer.layers.7.input_layernorm.weight', 'prompt_encoder.transfromer.layers.10.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.27.mlp.down_proj.weight', 'transformer.layers.2.post_attention_layernorm.weight', 'transformer.layers.6.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.10.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.16.mlp.gate_proj.weight', 'transformer.layers.20.self_attn.k_proj.weight', 'transformer.layers.7.mlp.up_proj.weight', 'transformer.layers.27.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.self_attn.v_proj.weight', 'transformer.layers.24.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.k_proj.weight', 'transformer.layers.23.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.30.input_layernorm.weight', 'transformer.layers.1.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.28.input_layernorm.weight', 'transformer.layers.2.self_attn.q_proj.weight', 'transformer.layers.22.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.26.self_attn.v_proj.weight', 'transformer.layers.1.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.30.self_attn.q_proj.weight', 'transformer.layers.15.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.12.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.27.self_attn.k_proj.weight', 'transformer.layers.8.self_attn.k_proj.weight', 'transformer.layers.19.post_attention_layernorm.weight', 'transformer.layers.1.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.0.post_attention_layernorm.weight', 'transformer.layers.11.self_attn.k_proj.weight', 'transformer.layers.28.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.24.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.17.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.25.post_attention_layernorm.weight', 'transformer.layers.4.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.5.input_layernorm.weight', 'prompt_encoder.transfromer.layers.5.mlp.up_proj.weight', 'transformer.layers.6.mlp.up_proj.weight', 'transformer.layers.1.mlp.gate_proj.weight', 'transformer.layers.0.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.15.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.19.input_layernorm.weight', 'transformer.layers.19.mlp.down_proj.weight', 'transformer.layers.8.input_layernorm.weight', 'transformer.layers.16.input_layernorm.weight', 'transformer.layers.31.mlp.down_proj.weight', 'transformer.layers.31.post_attention_layernorm.weight', 'transformer.layers.15.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.27.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.o_proj.weight', 'transformer.layers.12.self_attn.k_proj.weight', 'transformer.layers.31.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.5.mlp.down_proj.weight', 'transformer.layers.3.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.7.mlp.gate_proj.weight', 'transformer.layers.31.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.10.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.24.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.1.mlp.gate_proj.weight', 'transformer.layers.23.post_attention_layernorm.weight', 'transformer.layers.24.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.2.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.12.self_attn.v_proj.weight', 'transformer.layers.24.input_layernorm.weight', 'transformer.layers.6.mlp.down_proj.weight', 'transformer.norm.weight', 'prompt_encoder.transfromer.layers.7.self_attn.q_proj.weight', 'transformer.layers.26.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.13.input_layernorm.weight', 'transformer.layers.16.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.10.mlp.up_proj.weight', 'transformer.layers.31.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.18.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.31.self_attn.o_proj.weight', 'transformer.layers.30.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.v_proj.weight', 'transformer.layers.18.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.13.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.30.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.21.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.mlp.up_proj.weight', 'transformer.layers.14.self_attn.o_proj.weight', 'transformer.layers.8.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.18.input_layernorm.weight', 'prompt_encoder.transfromer.layers.22.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.19.mlp.up_proj.weight', 'transformer.layers.18.self_attn.v_proj.weight', 'transformer.layers.10.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.5.mlp.gate_proj.weight', 'transformer.layers.11.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.15.input_layernorm.weight', 'transformer.layers.7.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.26.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.13.self_attn.k_proj.weight', 'transformer.layers.29.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.7.post_attention_layernorm.weight', 'transformer.layers.29.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.18.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.1.input_layernorm.weight', 'prompt_encoder.transfromer.layers.25.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.8.mlp.gate_proj.weight', 'transformer.layers.12.post_attention_layernorm.weight', 'transformer.layers.17.mlp.down_proj.weight', 'transformer.layers.27.post_attention_layernorm.weight', 'transformer.layers.22.input_layernorm.weight', 'prompt_encoder.transfromer.layers.26.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.17.self_attn.k_proj.weight', 'transformer.layers.7.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.4.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.21.post_attention_layernorm.weight', 'transformer.layers.3.self_attn.q_proj.weight', 'transformer.layers.16.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.11.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.25.input_layernorm.weight', 'transformer.layers.27.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.27.input_layernorm.weight', 'transformer.layers.15.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.9.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.13.self_attn.q_proj.weight', 'transformer.layers.2.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.24.input_layernorm.weight', 'transformer.layers.1.input_layernorm.weight', 'transformer.layers.18.self_attn.k_proj.weight', 'transformer.layers.26.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.30.mlp.up_proj.weight', 'transformer.layers.8.self_attn.q_proj.weight', 'transformer.layers.9.input_layernorm.weight', 'prompt_encoder.transfromer.layers.21.self_attn.q_proj.weight', 'transformer.layers.2.self_attn.o_proj.weight', 'score.weight', 'transformer.layers.30.self_attn.k_proj.weight', 'transformer.layers.11.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.15.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.20.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.q_proj.weight', 'transformer.layers.8.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.17.input_layernorm.weight', 'transformer.layers.26.input_layernorm.weight', 'prompt_encoder.transfromer.layers.28.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.31.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.o_proj.weight', 'transformer.layers.10.self_attn.o_proj.weight', 'transformer.layers.26.self_attn.q_proj.weight', 'transformer.layers.17.self_attn.o_proj.weight', 'transformer.layers.20.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.12.self_attn.q_proj.weight', 'transformer.layers.15.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.15.self_attn.v_proj.weight', 'prompt_encoder.transfromer.embed_tokens.weight', 'prompt_encoder.transfromer.layers.30.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.30.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.2.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.post_attention_layernorm.weight', 'transformer.layers.16.self_attn.o_proj.weight', 'transformer.layers.0.self_attn.v_proj.weight', 'transformer.layers.0.post_attention_layernorm.weight', 'transformer.layers.0.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.21.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.16.post_attention_layernorm.weight', 'transformer.layers.29.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.17.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.12.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.31.mlp.up_proj.weight', 'transformer.layers.10.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.17.post_attention_layernorm.weight', 'transformer.layers.25.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.22.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.19.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.16.input_layernorm.weight', 'prompt_encoder.transfromer.layers.17.self_attn.q_proj.weight', 'transformer.layers.16.post_attention_layernorm.weight', 'transformer.layers.4.mlp.gate_proj.weight', 'transformer.layers.28.self_attn.q_proj.weight', 'transformer.layers.6.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.v_proj.weight', 'transformer.layers.9.self_attn.k_proj.weight', 'transformer.layers.7.input_layernorm.weight', 'transformer.layers.25.input_layernorm.weight', 'transformer.layers.20.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.20.post_attention_layernorm.weight', 'transformer.layers.7.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.19.post_attention_layernorm.weight', 'transformer.layers.1.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.10.input_layernorm.weight', 'prompt_encoder.transfromer.layers.1.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.7.self_attn.k_proj.weight', 'transformer.embed_tokens.weight', 'prompt_encoder.transfromer.layers.29.mlp.up_proj.weight', 'transformer.layers.30.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.q_proj.weight', 'transformer.layers.11.input_layernorm.weight', 'prompt_encoder.transfromer.layers.22.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.29.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.19.self_attn.v_proj.weight', 'transformer.layers.5.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.o_proj.weight', 'transformer.layers.20.mlp.down_proj.weight', 'transformer.layers.29.post_attention_layernorm.weight', 'transformer.layers.4.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.k_proj.weight', 'transformer.layers.9.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.v_proj.weight', 'transformer.layers.17.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.16.self_attn.q_proj.weight', 'transformer.layers.3.self_attn.k_proj.weight', 'transformer.layers.12.input_layernorm.weight', 'prompt_encoder.transfromer.layers.5.post_attention_layernorm.weight', 'transformer.layers.19.mlp.gate_proj.weight', 'transformer.layers.26.mlp.up_proj.weight', 'transformer.layers.21.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.9.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.8.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.k_proj.weight', 'transformer.layers.21.self_attn.o_proj.weight', 'transformer.layers.28.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.27.mlp.gate_proj.weight', 'transformer.layers.17.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.k_proj.weight', 'transformer.layers.9.mlp.up_proj.weight', 'transformer.layers.4.self_attn.v_proj.weight', 'transformer.layers.5.input_layernorm.weight', 'transformer.layers.26.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.25.mlp.gate_proj.weight', 'transformer.layers.20.mlp.gate_proj.weight', 'transformer.layers.6.mlp.gate_proj.weight', 'transformer.layers.15.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.4.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.27.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.15.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.29.self_attn.o_proj.weight', 'transformer.layers.23.self_attn.q_proj.weight', 'transformer.layers.17.input_layernorm.weight', 'transformer.layers.18.self_attn.o_proj.weight', 'transformer.layers.29.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.14.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.31.post_attention_layernorm.weight', 'transformer.layers.0.self_attn.o_proj.weight', 'transformer.layers.19.self_attn.o_proj.weight', 'transformer.layers.4.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.17.self_attn.o_proj.weight', 'transformer.layers.30.input_layernorm.weight', 'transformer.layers.25.mlp.down_proj.weight', 'transformer.layers.27.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.20.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.6.mlp.gate_proj.weight', 'transformer.layers.20.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.self_attn.q_proj.weight', 'transformer.layers.4.mlp.up_proj.weight', 'transformer.layers.15.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.12.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.24.mlp.up_proj.weight', 'transformer.layers.30.self_attn.v_proj.weight', 'transformer.layers.17.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.14.mlp.up_proj.weight', 'transformer.layers.8.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.13.self_attn.v_proj.weight', 'transformer.layers.26.self_attn.v_proj.weight', 'transformer.layers.22.self_attn.k_proj.weight', 'transformer.layers.15.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.20.input_layernorm.weight', 'prompt_encoder.transfromer.layers.10.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.13.self_attn.o_proj.weight', 'transformer.layers.25.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.8.post_attention_layernorm.weight', 'transformer.layers.5.mlp.up_proj.weight', 'transformer.layers.11.mlp.up_proj.weight', 'transformer.layers.10.mlp.gate_proj.weight', 'transformer.layers.13.post_attention_layernorm.weight', 'transformer.layers.13.self_attn.k_proj.weight', 'transformer.layers.27.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.31.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.1.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.23.self_attn.v_proj.weight', 'transformer.layers.25.self_attn.v_proj.weight', 'transformer.layers.13.mlp.gate_proj.weight', 'transformer.layers.5.self_attn.o_proj.weight', 'transformer.layers.21.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.11.post_attention_layernorm.weight', 'transformer.layers.24.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.26.self_attn.q_proj.weight', 'transformer.layers.12.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.19.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.14.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.14.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.9.mlp.gate_proj.weight', 'transformer.layers.2.mlp.down_proj.weight', 'transformer.layers.27.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.11.input_layernorm.weight', 'transformer.layers.12.mlp.down_proj.weight', 'transformer.layers.16.mlp.gate_proj.weight', 'transformer.layers.12.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.18.self_attn.q_proj.weight', 'transformer.layers.12.self_attn.o_proj.weight', 'transformer.layers.14.mlp.gate_proj.weight', 'transformer.layers.21.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.10.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.3.input_layernorm.weight', 'transformer.layers.24.self_attn.k_proj.weight', 'transformer.layers.11.post_attention_layernorm.weight', 'transformer.layers.22.self_attn.o_proj.weight', 'transformer.layers.29.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.7.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.o_proj.weight', 'transformer.layers.23.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.29.self_attn.v_proj.weight', 'transformer.layers.17.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.7.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.16.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.18.mlp.gate_proj.weight', 'transformer.layers.31.mlp.up_proj.weight', 'transformer.layers.3.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.q_proj.weight', 'transformer.layers.19.self_attn.q_proj.weight', 'transformer.layers.10.input_layernorm.weight', 'transformer.layers.23.mlp.gate_proj.weight', 'transformer.layers.30.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.28.mlp.up_proj.weight', 'transformer.layers.3.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.o_proj.weight', 'transformer.layers.5.mlp.gate_proj.weight', 'transformer.layers.13.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.6.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.24.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.26.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.22.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.2.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.29.post_attention_layernorm.weight', 'transformer.layers.5.post_attention_layernorm.weight', 'transformer.layers.12.self_attn.q_proj.weight', 'transformer.layers.25.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.0.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.16.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.18.post_attention_layernorm.weight', 'transformer.layers.31.self_attn.k_proj.weight', 'transformer.layers.14.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.15.mlp.up_proj.weight', 'transformer.layers.0.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.7.mlp.down_proj.weight', 'transformer.layers.22.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.15.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.input_layernorm.weight', 'transformer.layers.6.post_attention_layernorm.weight', 'transformer.layers.15.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.17.mlp.gate_proj.weight', 'transformer.layers.24.mlp.gate_proj.weight', 'transformer.layers.27.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.29.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.27.mlp.up_proj.weight', 'transformer.layers.6.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.28.mlp.gate_proj.weight', 'transformer.layers.20.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.24.post_attention_layernorm.weight', 'transformer.layers.22.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.31.mlp.gate_proj.weight', 'transformer.layers.14.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.15.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.26.mlp.up_proj.weight', 'transformer.layers.24.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.v_proj.weight', 'transformer.layers.2.self_attn.v_proj.weight', 'transformer.layers.6.self_attn.k_proj.weight', 'transformer.layers.0.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.23.mlp.down_proj.weight', 'transformer.layers.8.mlp.gate_proj.weight', 'transformer.layers.9.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.16.self_attn.k_proj.weight', 'transformer.layers.2.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.30.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.3.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.o_proj.weight', 'prompt_encoder.transfromer.norm.weight', 'transformer.layers.18.input_layernorm.weight', 'transformer.layers.22.self_attn.q_proj.weight', 'transformer.layers.23.input_layernorm.weight', 'prompt_encoder.transfromer.layers.16.self_attn.v_proj.weight', 'transformer.layers.11.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.o_proj.weight', 'transformer.layers.5.self_attn.q_proj.weight', 'transformer.layers.7.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.22.self_attn.k_proj.weight', 'transformer.layers.16.mlp.down_proj.weight', 'transformer.layers.30.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.19.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.6.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.3.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.13.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.2.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.23.self_attn.q_proj.weight', 'transformer.layers.21.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.k_proj.weight', 'transformer.layers.8.mlp.down_proj.weight', 'transformer.layers.21.mlp.up_proj.weight', 'transformer.layers.18.mlp.up_proj.weight', 'transformer.layers.13.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.mlp.down_proj.weight', 'transformer.layers.17.mlp.up_proj.weight', 'transformer.layers.6.input_layernorm.weight', 'prompt_encoder.transfromer.layers.18.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.30.self_attn.o_proj.weight', 'transformer.layers.10.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.k_proj.weight', 'transformer.layers.19.self_attn.v_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from mistralSKT import  PrefixForSequenceClassification\n",
    "\n",
    "model = PrefixForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fbd31bc-596b-4012-8925-be431b9fe680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 7110713346\n",
      "Trainable Parameters: 53250\n",
      "Percentage Trainable: 0.00074887001358246003%\n"
     ]
    }
   ],
   "source": [
    "# Total number of parameters in the model\n",
    "total_parameters = model.num_parameters()\n",
    "\n",
    "# Total number of trainable parameters in the model\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Calculate the percentage of trainable parameters\n",
    "percentage_trainable = (trainable_parameters / total_parameters) * 100\n",
    "\n",
    "print(f\"Total Parameters: {total_parameters}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters}\")\n",
    "print(f\"Percentage Trainable: {percentage_trainable:.20f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171405eb-cba9-4ae0-a2bd-7e85df4adae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47afa401-33fc-4d55-bddc-e9e42d4a0607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42095' max='42095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42095/42095 14:34:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.520159</td>\n",
       "      <td>0.744365</td>\n",
       "      <td>0.743706</td>\n",
       "      <td>0.743033</td>\n",
       "      <td>0.743119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.412051</td>\n",
       "      <td>0.818641</td>\n",
       "      <td>0.806917</td>\n",
       "      <td>0.803554</td>\n",
       "      <td>0.805046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.327493</td>\n",
       "      <td>0.876178</td>\n",
       "      <td>0.873137</td>\n",
       "      <td>0.873470</td>\n",
       "      <td>0.873853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.331070</td>\n",
       "      <td>0.876700</td>\n",
       "      <td>0.861823</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>0.863532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.268105</td>\n",
       "      <td>0.908819</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.908255</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.256878</td>\n",
       "      <td>0.924455</td>\n",
       "      <td>0.924160</td>\n",
       "      <td>0.924264</td>\n",
       "      <td>0.924312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.341146</td>\n",
       "      <td>0.911654</td>\n",
       "      <td>0.911773</td>\n",
       "      <td>0.911683</td>\n",
       "      <td>0.911697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.287382</td>\n",
       "      <td>0.921371</td>\n",
       "      <td>0.921245</td>\n",
       "      <td>0.920871</td>\n",
       "      <td>0.920872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.322593</td>\n",
       "      <td>0.914650</td>\n",
       "      <td>0.912267</td>\n",
       "      <td>0.912641</td>\n",
       "      <td>0.912844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>0.312483</td>\n",
       "      <td>0.923351</td>\n",
       "      <td>0.922992</td>\n",
       "      <td>0.923112</td>\n",
       "      <td>0.923165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.319226</td>\n",
       "      <td>0.935989</td>\n",
       "      <td>0.936053</td>\n",
       "      <td>0.935779</td>\n",
       "      <td>0.935780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.435189</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.915062</td>\n",
       "      <td>0.915138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.328073</td>\n",
       "      <td>0.926526</td>\n",
       "      <td>0.925034</td>\n",
       "      <td>0.925338</td>\n",
       "      <td>0.925459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.284038</td>\n",
       "      <td>0.932639</td>\n",
       "      <td>0.932127</td>\n",
       "      <td>0.932284</td>\n",
       "      <td>0.932339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.335852</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.927875</td>\n",
       "      <td>0.927745</td>\n",
       "      <td>0.927752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.338512</td>\n",
       "      <td>0.930040</td>\n",
       "      <td>0.930001</td>\n",
       "      <td>0.930019</td>\n",
       "      <td>0.930046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.353689</td>\n",
       "      <td>0.931059</td>\n",
       "      <td>0.930549</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>0.930046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.316198</td>\n",
       "      <td>0.939244</td>\n",
       "      <td>0.939389</td>\n",
       "      <td>0.939216</td>\n",
       "      <td>0.939220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.321808</td>\n",
       "      <td>0.940418</td>\n",
       "      <td>0.940557</td>\n",
       "      <td>0.940364</td>\n",
       "      <td>0.940367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.355380</td>\n",
       "      <td>0.922359</td>\n",
       "      <td>0.921782</td>\n",
       "      <td>0.921949</td>\n",
       "      <td>0.922018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.263935</td>\n",
       "      <td>0.934614</td>\n",
       "      <td>0.934758</td>\n",
       "      <td>0.934626</td>\n",
       "      <td>0.934633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.939201</td>\n",
       "      <td>0.939347</td>\n",
       "      <td>0.939214</td>\n",
       "      <td>0.939220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.361402</td>\n",
       "      <td>0.940954</td>\n",
       "      <td>0.940768</td>\n",
       "      <td>0.940366</td>\n",
       "      <td>0.940367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.326340</td>\n",
       "      <td>0.942618</td>\n",
       "      <td>0.942683</td>\n",
       "      <td>0.942646</td>\n",
       "      <td>0.942661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.405449</td>\n",
       "      <td>0.926754</td>\n",
       "      <td>0.923655</td>\n",
       "      <td>0.924101</td>\n",
       "      <td>0.924312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.362384</td>\n",
       "      <td>0.939178</td>\n",
       "      <td>0.939305</td>\n",
       "      <td>0.939211</td>\n",
       "      <td>0.939220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.352250</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.938968</td>\n",
       "      <td>0.939162</td>\n",
       "      <td>0.939220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.365266</td>\n",
       "      <td>0.940809</td>\n",
       "      <td>0.940726</td>\n",
       "      <td>0.940367</td>\n",
       "      <td>0.940367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.324697</td>\n",
       "      <td>0.944069</td>\n",
       "      <td>0.944104</td>\n",
       "      <td>0.943807</td>\n",
       "      <td>0.943807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.323784</td>\n",
       "      <td>0.944978</td>\n",
       "      <td>0.944893</td>\n",
       "      <td>0.944931</td>\n",
       "      <td>0.944954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.311641</td>\n",
       "      <td>0.948363</td>\n",
       "      <td>0.948398</td>\n",
       "      <td>0.948379</td>\n",
       "      <td>0.948394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.343852</td>\n",
       "      <td>0.940347</td>\n",
       "      <td>0.940347</td>\n",
       "      <td>0.940347</td>\n",
       "      <td>0.940367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.388613</td>\n",
       "      <td>0.941599</td>\n",
       "      <td>0.939926</td>\n",
       "      <td>0.940265</td>\n",
       "      <td>0.940367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.321564</td>\n",
       "      <td>0.948847</td>\n",
       "      <td>0.948146</td>\n",
       "      <td>0.948345</td>\n",
       "      <td>0.948394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.371672</td>\n",
       "      <td>0.941633</td>\n",
       "      <td>0.941389</td>\n",
       "      <td>0.941480</td>\n",
       "      <td>0.941514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.397868</td>\n",
       "      <td>0.939201</td>\n",
       "      <td>0.939347</td>\n",
       "      <td>0.939214</td>\n",
       "      <td>0.939220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.345181</td>\n",
       "      <td>0.942920</td>\n",
       "      <td>0.942473</td>\n",
       "      <td>0.942617</td>\n",
       "      <td>0.942661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.335135</td>\n",
       "      <td>0.947514</td>\n",
       "      <td>0.947062</td>\n",
       "      <td>0.947208</td>\n",
       "      <td>0.947248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.345302</td>\n",
       "      <td>0.949567</td>\n",
       "      <td>0.949482</td>\n",
       "      <td>0.949520</td>\n",
       "      <td>0.949541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>0.317653</td>\n",
       "      <td>0.953111</td>\n",
       "      <td>0.952861</td>\n",
       "      <td>0.952954</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.305122</td>\n",
       "      <td>0.954088</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.954117</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>0.950711</td>\n",
       "      <td>0.950861</td>\n",
       "      <td>0.950685</td>\n",
       "      <td>0.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>0.242632</td>\n",
       "      <td>0.953066</td>\n",
       "      <td>0.953197</td>\n",
       "      <td>0.952980</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.363891</td>\n",
       "      <td>0.947370</td>\n",
       "      <td>0.947483</td>\n",
       "      <td>0.947247</td>\n",
       "      <td>0.947248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.287029</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>0.951945</td>\n",
       "      <td>0.951829</td>\n",
       "      <td>0.951835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.353305</td>\n",
       "      <td>0.950691</td>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.950669</td>\n",
       "      <td>0.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.349196</td>\n",
       "      <td>0.952985</td>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.952964</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.343346</td>\n",
       "      <td>0.950952</td>\n",
       "      <td>0.950987</td>\n",
       "      <td>0.950688</td>\n",
       "      <td>0.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.264048</td>\n",
       "      <td>0.954524</td>\n",
       "      <td>0.953903</td>\n",
       "      <td>0.954088</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.313007</td>\n",
       "      <td>0.951145</td>\n",
       "      <td>0.950440</td>\n",
       "      <td>0.950641</td>\n",
       "      <td>0.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.252400</td>\n",
       "      <td>0.275269</td>\n",
       "      <td>0.954302</td>\n",
       "      <td>0.953987</td>\n",
       "      <td>0.954099</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.293127</td>\n",
       "      <td>0.952107</td>\n",
       "      <td>0.951650</td>\n",
       "      <td>0.951798</td>\n",
       "      <td>0.951835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.296034</td>\n",
       "      <td>0.956422</td>\n",
       "      <td>0.956576</td>\n",
       "      <td>0.956418</td>\n",
       "      <td>0.956422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.253233</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>0.954281</td>\n",
       "      <td>0.954125</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.371154</td>\n",
       "      <td>0.948847</td>\n",
       "      <td>0.948146</td>\n",
       "      <td>0.948345</td>\n",
       "      <td>0.948394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.311122</td>\n",
       "      <td>0.954725</td>\n",
       "      <td>0.954534</td>\n",
       "      <td>0.954127</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.271025</td>\n",
       "      <td>0.957539</td>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.957556</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.333534</td>\n",
       "      <td>0.948520</td>\n",
       "      <td>0.948272</td>\n",
       "      <td>0.948365</td>\n",
       "      <td>0.948394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.305166</td>\n",
       "      <td>0.950815</td>\n",
       "      <td>0.950566</td>\n",
       "      <td>0.950659</td>\n",
       "      <td>0.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.300085</td>\n",
       "      <td>0.953005</td>\n",
       "      <td>0.953155</td>\n",
       "      <td>0.952979</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.290653</td>\n",
       "      <td>0.950952</td>\n",
       "      <td>0.950987</td>\n",
       "      <td>0.950688</td>\n",
       "      <td>0.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.281405</td>\n",
       "      <td>0.954088</td>\n",
       "      <td>0.954155</td>\n",
       "      <td>0.954117</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.218093</td>\n",
       "      <td>0.959821</td>\n",
       "      <td>0.959954</td>\n",
       "      <td>0.959856</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.234032</td>\n",
       "      <td>0.956822</td>\n",
       "      <td>0.956197</td>\n",
       "      <td>0.956383</td>\n",
       "      <td>0.956422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.259104</td>\n",
       "      <td>0.954251</td>\n",
       "      <td>0.954366</td>\n",
       "      <td>0.954127</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.265332</td>\n",
       "      <td>0.955230</td>\n",
       "      <td>0.955323</td>\n",
       "      <td>0.955265</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.237668</td>\n",
       "      <td>0.958929</td>\n",
       "      <td>0.958996</td>\n",
       "      <td>0.958715</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.213533</td>\n",
       "      <td>0.958767</td>\n",
       "      <td>0.958912</td>\n",
       "      <td>0.958714</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>0.254518</td>\n",
       "      <td>0.954578</td>\n",
       "      <td>0.954492</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.957550</td>\n",
       "      <td>0.957702</td>\n",
       "      <td>0.957564</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.954578</td>\n",
       "      <td>0.954492</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.247942</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.963459</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.235409</td>\n",
       "      <td>0.959038</td>\n",
       "      <td>0.959038</td>\n",
       "      <td>0.958716</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>0.274023</td>\n",
       "      <td>0.957021</td>\n",
       "      <td>0.956828</td>\n",
       "      <td>0.956421</td>\n",
       "      <td>0.956422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.211789</td>\n",
       "      <td>0.958670</td>\n",
       "      <td>0.958786</td>\n",
       "      <td>0.958708</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.290217</td>\n",
       "      <td>0.957734</td>\n",
       "      <td>0.957828</td>\n",
       "      <td>0.957568</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.216749</td>\n",
       "      <td>0.964535</td>\n",
       "      <td>0.964669</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.265827</td>\n",
       "      <td>0.955360</td>\n",
       "      <td>0.955492</td>\n",
       "      <td>0.955274</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.268424</td>\n",
       "      <td>0.957550</td>\n",
       "      <td>0.957702</td>\n",
       "      <td>0.957564</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.224728</td>\n",
       "      <td>0.963258</td>\n",
       "      <td>0.963375</td>\n",
       "      <td>0.963296</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.289749</td>\n",
       "      <td>0.956515</td>\n",
       "      <td>0.956323</td>\n",
       "      <td>0.956399</td>\n",
       "      <td>0.956422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.257330</td>\n",
       "      <td>0.959834</td>\n",
       "      <td>0.959870</td>\n",
       "      <td>0.959851</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>0.269625</td>\n",
       "      <td>0.962219</td>\n",
       "      <td>0.962080</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.266225</td>\n",
       "      <td>0.959844</td>\n",
       "      <td>0.959996</td>\n",
       "      <td>0.959858</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.253138</td>\n",
       "      <td>0.963258</td>\n",
       "      <td>0.963375</td>\n",
       "      <td>0.963296</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>0.251578</td>\n",
       "      <td>0.962115</td>\n",
       "      <td>0.962248</td>\n",
       "      <td>0.962150</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.298260</td>\n",
       "      <td>0.955440</td>\n",
       "      <td>0.955534</td>\n",
       "      <td>0.955275</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.270247</td>\n",
       "      <td>0.958838</td>\n",
       "      <td>0.958954</td>\n",
       "      <td>0.958715</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.251334</td>\n",
       "      <td>0.958811</td>\n",
       "      <td>0.958617</td>\n",
       "      <td>0.958694</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.249960</td>\n",
       "      <td>0.958746</td>\n",
       "      <td>0.958660</td>\n",
       "      <td>0.958698</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.374466</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.951835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.240656</td>\n",
       "      <td>0.957702</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.957544</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.346449</td>\n",
       "      <td>0.954082</td>\n",
       "      <td>0.954197</td>\n",
       "      <td>0.954120</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.338845</td>\n",
       "      <td>0.955230</td>\n",
       "      <td>0.955323</td>\n",
       "      <td>0.955265</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.250257</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.963459</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.327481</td>\n",
       "      <td>0.959869</td>\n",
       "      <td>0.959828</td>\n",
       "      <td>0.959847</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.334410</td>\n",
       "      <td>0.957795</td>\n",
       "      <td>0.957407</td>\n",
       "      <td>0.957539</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.318445</td>\n",
       "      <td>0.952963</td>\n",
       "      <td>0.953113</td>\n",
       "      <td>0.952977</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.263600</td>\n",
       "      <td>0.295725</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.255072</td>\n",
       "      <td>0.962179</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.962154</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.222664</td>\n",
       "      <td>0.965558</td>\n",
       "      <td>0.965627</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.263217</td>\n",
       "      <td>0.963264</td>\n",
       "      <td>0.963332</td>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20600</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.276003</td>\n",
       "      <td>0.960028</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.959862</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20800</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.261115</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.963459</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.253174</td>\n",
       "      <td>0.958746</td>\n",
       "      <td>0.958660</td>\n",
       "      <td>0.958698</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21200</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.270978</td>\n",
       "      <td>0.962128</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21400</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.225143</td>\n",
       "      <td>0.962179</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.962154</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.235574</td>\n",
       "      <td>0.960964</td>\n",
       "      <td>0.961080</td>\n",
       "      <td>0.961002</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21800</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.258057</td>\n",
       "      <td>0.959998</td>\n",
       "      <td>0.959744</td>\n",
       "      <td>0.959839</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.257591</td>\n",
       "      <td>0.962219</td>\n",
       "      <td>0.962080</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22200</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.227215</td>\n",
       "      <td>0.956822</td>\n",
       "      <td>0.956197</td>\n",
       "      <td>0.956383</td>\n",
       "      <td>0.956422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22400</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.228734</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22600</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.217827</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.222688</td>\n",
       "      <td>0.965596</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.965593</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.210726</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23200</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.269344</td>\n",
       "      <td>0.961041</td>\n",
       "      <td>0.960954</td>\n",
       "      <td>0.960993</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23400</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>0.243951</td>\n",
       "      <td>0.961041</td>\n",
       "      <td>0.960954</td>\n",
       "      <td>0.960993</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23600</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.226570</td>\n",
       "      <td>0.960204</td>\n",
       "      <td>0.959659</td>\n",
       "      <td>0.959829</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23800</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.224886</td>\n",
       "      <td>0.965551</td>\n",
       "      <td>0.965669</td>\n",
       "      <td>0.965590</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.247854</td>\n",
       "      <td>0.966716</td>\n",
       "      <td>0.966753</td>\n",
       "      <td>0.966733</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24200</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.236488</td>\n",
       "      <td>0.965558</td>\n",
       "      <td>0.965627</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24400</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.221855</td>\n",
       "      <td>0.965558</td>\n",
       "      <td>0.965627</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24600</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.228146</td>\n",
       "      <td>0.964535</td>\n",
       "      <td>0.964669</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24800</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.238328</td>\n",
       "      <td>0.964535</td>\n",
       "      <td>0.964669</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.237586</td>\n",
       "      <td>0.960996</td>\n",
       "      <td>0.960996</td>\n",
       "      <td>0.960996</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.222705</td>\n",
       "      <td>0.964408</td>\n",
       "      <td>0.964543</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25400</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.217191</td>\n",
       "      <td>0.966767</td>\n",
       "      <td>0.966921</td>\n",
       "      <td>0.966741</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25600</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.274550</td>\n",
       "      <td>0.960996</td>\n",
       "      <td>0.960996</td>\n",
       "      <td>0.960996</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25800</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.236575</td>\n",
       "      <td>0.964422</td>\n",
       "      <td>0.964459</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.223356</td>\n",
       "      <td>0.965720</td>\n",
       "      <td>0.965837</td>\n",
       "      <td>0.965596</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26200</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.225379</td>\n",
       "      <td>0.963426</td>\n",
       "      <td>0.963543</td>\n",
       "      <td>0.963302</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.242041</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26600</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.217516</td>\n",
       "      <td>0.970151</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>0.970180</td>\n",
       "      <td>0.970183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26800</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.234036</td>\n",
       "      <td>0.967858</td>\n",
       "      <td>0.968005</td>\n",
       "      <td>0.967886</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.255778</td>\n",
       "      <td>0.963426</td>\n",
       "      <td>0.963543</td>\n",
       "      <td>0.963302</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27200</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.215057</td>\n",
       "      <td>0.968996</td>\n",
       "      <td>0.969132</td>\n",
       "      <td>0.969032</td>\n",
       "      <td>0.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27400</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.237015</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.243194</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27800</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.253311</td>\n",
       "      <td>0.963401</td>\n",
       "      <td>0.963206</td>\n",
       "      <td>0.963283</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.244918</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28200</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.218434</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28400</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.235310</td>\n",
       "      <td>0.965648</td>\n",
       "      <td>0.965795</td>\n",
       "      <td>0.965595</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28600</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.205102</td>\n",
       "      <td>0.966767</td>\n",
       "      <td>0.966921</td>\n",
       "      <td>0.966741</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28800</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.246143</td>\n",
       "      <td>0.961223</td>\n",
       "      <td>0.961291</td>\n",
       "      <td>0.961009</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.249304</td>\n",
       "      <td>0.964431</td>\n",
       "      <td>0.964585</td>\n",
       "      <td>0.964446</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29200</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.242555</td>\n",
       "      <td>0.964431</td>\n",
       "      <td>0.964585</td>\n",
       "      <td>0.964446</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29400</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.264825</td>\n",
       "      <td>0.964535</td>\n",
       "      <td>0.964669</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29600</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.271903</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.963459</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29800</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.247321</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>0.962128</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.962156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.234707</td>\n",
       "      <td>0.969018</td>\n",
       "      <td>0.969174</td>\n",
       "      <td>0.969033</td>\n",
       "      <td>0.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30400</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.233484</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30600</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.229255</td>\n",
       "      <td>0.965558</td>\n",
       "      <td>0.965627</td>\n",
       "      <td>0.965587</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30800</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>0.247637</td>\n",
       "      <td>0.965648</td>\n",
       "      <td>0.965795</td>\n",
       "      <td>0.965595</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.240540</td>\n",
       "      <td>0.964422</td>\n",
       "      <td>0.964459</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31200</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.230824</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31400</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.239637</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31600</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.239585</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31800</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.253471</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32200</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.232428</td>\n",
       "      <td>0.964422</td>\n",
       "      <td>0.964459</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.248779</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963290</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32600</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.241145</td>\n",
       "      <td>0.964458</td>\n",
       "      <td>0.964417</td>\n",
       "      <td>0.964436</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32800</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.251492</td>\n",
       "      <td>0.964458</td>\n",
       "      <td>0.964417</td>\n",
       "      <td>0.964436</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.269134</td>\n",
       "      <td>0.958811</td>\n",
       "      <td>0.958617</td>\n",
       "      <td>0.958694</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33200</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.260566</td>\n",
       "      <td>0.963264</td>\n",
       "      <td>0.963332</td>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33400</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.248082</td>\n",
       "      <td>0.965596</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.965593</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33600</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.220670</td>\n",
       "      <td>0.967858</td>\n",
       "      <td>0.968005</td>\n",
       "      <td>0.967886</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33800</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.237430</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.229998</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34200</td>\n",
       "      <td>0.150600</td>\n",
       "      <td>0.237820</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34400</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34600</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.246066</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34800</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.236822</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.247946</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35200</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.237474</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35400</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.228056</td>\n",
       "      <td>0.968996</td>\n",
       "      <td>0.969132</td>\n",
       "      <td>0.969032</td>\n",
       "      <td>0.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35600</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.220484</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35800</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.221853</td>\n",
       "      <td>0.968996</td>\n",
       "      <td>0.969132</td>\n",
       "      <td>0.969032</td>\n",
       "      <td>0.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.232594</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36200</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.221449</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36400</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.225070</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36600</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.232981</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36800</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.230835</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.238665</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37200</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.247985</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37400</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>0.250697</td>\n",
       "      <td>0.964422</td>\n",
       "      <td>0.964459</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37600</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.239690</td>\n",
       "      <td>0.967845</td>\n",
       "      <td>0.967963</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37800</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.252144</td>\n",
       "      <td>0.965585</td>\n",
       "      <td>0.965585</td>\n",
       "      <td>0.965585</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.244097</td>\n",
       "      <td>0.970139</td>\n",
       "      <td>0.970258</td>\n",
       "      <td>0.970178</td>\n",
       "      <td>0.970183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38200</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.248745</td>\n",
       "      <td>0.967852</td>\n",
       "      <td>0.967921</td>\n",
       "      <td>0.967882</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38400</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38600</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.257729</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38800</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.243167</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.254904</td>\n",
       "      <td>0.965585</td>\n",
       "      <td>0.965585</td>\n",
       "      <td>0.965585</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39200</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.249059</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39400</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.256752</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39600</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.245229</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39800</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.241033</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.250548</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40200</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.966795</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40400</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.257225</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40600</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.253903</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40800</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.251479</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.250736</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41200</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>0.249272</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41400</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.250281</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41600</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>0.966725</td>\n",
       "      <td>0.966879</td>\n",
       "      <td>0.966740</td>\n",
       "      <td>0.966743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41800</td>\n",
       "      <td>0.180200</td>\n",
       "      <td>0.244541</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.244448</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.965711</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.965596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removed shared tensor {'prompt_encoder.transfromer.layers.20.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.6.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.31.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.13.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.28.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.24.input_layernorm.weight', 'prompt_encoder.transfromer.layers.12.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.24.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.3.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.30.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.14.input_layernorm.weight', 'prompt_encoder.transfromer.layers.1.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.24.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.12.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.23.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.15.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.29.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.14.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.13.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.27.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.20.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.20.input_layernorm.weight', 'prompt_encoder.transfromer.layers.10.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.13.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.22.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.8.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.7.input_layernorm.weight', 'prompt_encoder.transfromer.layers.10.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.5.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.26.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.15.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.27.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.20.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.10.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.16.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.31.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.1.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.23.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.11.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.17.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.28.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.31.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.11.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.12.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.30.input_layernorm.weight', 'prompt_encoder.transfromer.layers.26.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.28.input_layernorm.weight', 'prompt_encoder.transfromer.layers.17.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.12.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.19.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.14.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.15.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.14.mlp.gate_proj.weight', 'prompt_encoder.transfromer.embed_tokens.weight', 'prompt_encoder.transfromer.layers.26.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.30.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.20.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.2.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.9.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.23.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.30.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.30.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.12.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.27.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.21.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.16.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.11.input_layernorm.weight', 'prompt_encoder.transfromer.layers.17.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.12.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.18.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.27.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.0.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.24.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.31.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.17.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.24.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.17.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.21.input_layernorm.weight', 'prompt_encoder.transfromer.layers.6.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.25.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.18.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.5.input_layernorm.weight', 'prompt_encoder.transfromer.layers.22.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.23.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.19.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.5.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.10.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.16.input_layernorm.weight', 'prompt_encoder.transfromer.layers.17.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.18.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.3.input_layernorm.weight', 'prompt_encoder.transfromer.layers.15.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.19.input_layernorm.weight', 'prompt_encoder.transfromer.layers.3.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.7.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.12.input_layernorm.weight', 'prompt_encoder.transfromer.layers.6.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.8.input_layernorm.weight', 'prompt_encoder.transfromer.layers.22.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.22.input_layernorm.weight', 'prompt_encoder.transfromer.layers.29.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.20.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.7.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.19.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.27.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.16.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.10.input_layernorm.weight', 'prompt_encoder.transfromer.layers.18.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.1.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.7.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.2.input_layernorm.weight', 'prompt_encoder.transfromer.layers.29.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.7.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.5.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.22.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.29.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.12.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.28.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.10.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.8.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.24.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.19.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.1.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.6.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.24.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.26.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.22.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.2.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.2.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.6.input_layernorm.weight', 'prompt_encoder.transfromer.layers.12.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.11.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.7.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.29.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.8.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.0.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.13.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.13.input_layernorm.weight', 'prompt_encoder.transfromer.layers.16.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.18.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.15.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.0.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.15.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.7.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.23.input_layernorm.weight', 'prompt_encoder.transfromer.layers.11.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.3.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.16.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.17.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.29.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.27.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.2.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.6.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.28.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.0.input_layernorm.weight', 'prompt_encoder.transfromer.layers.10.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.28.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.18.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.31.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.13.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.30.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.24.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.19.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.21.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.4.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.5.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.25.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.29.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.15.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.9.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.18.input_layernorm.weight', 'prompt_encoder.transfromer.layers.0.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.8.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.19.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.22.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.26.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.11.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.5.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.9.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.input_layernorm.weight', 'prompt_encoder.transfromer.layers.15.input_layernorm.weight', 'prompt_encoder.transfromer.layers.23.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.23.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.27.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.26.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.13.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.16.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.16.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.21.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.7.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.18.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.4.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.10.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.26.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.26.input_layernorm.weight', 'prompt_encoder.transfromer.layers.27.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.1.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.4.input_layernorm.weight', 'prompt_encoder.transfromer.layers.1.input_layernorm.weight', 'prompt_encoder.transfromer.layers.19.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.30.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.3.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.20.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.25.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.30.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.15.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.8.mlp.gate_proj.weight', 'prompt_encoder.transfromer.norm.weight', 'prompt_encoder.transfromer.layers.29.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.16.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.22.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.5.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.21.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.26.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.22.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.8.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.0.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.17.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.19.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.4.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.6.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.9.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.3.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.13.mlp.gate_proj.weight', 'prompt_encoder.transfromer.layers.2.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.10.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.21.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.9.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.23.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.4.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.14.self_attn.q_proj.weight', 'prompt_encoder.transfromer.layers.24.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.11.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.7.mlp.up_proj.weight', 'prompt_encoder.transfromer.layers.14.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.25.input_layernorm.weight', 'prompt_encoder.transfromer.layers.31.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.25.mlp.down_proj.weight', 'prompt_encoder.transfromer.layers.17.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.13.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.27.input_layernorm.weight', 'prompt_encoder.transfromer.layers.18.self_attn.v_proj.weight', 'prompt_encoder.transfromer.layers.4.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.30.self_attn.o_proj.weight', 'prompt_encoder.transfromer.layers.9.post_attention_layernorm.weight', 'prompt_encoder.transfromer.layers.28.self_attn.k_proj.weight', 'prompt_encoder.transfromer.layers.29.self_attn.q_proj.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "Could not locate the best model at ./r_task/checkpoint-28600/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=42095, training_loss=0.22266500411626633, metrics={'train_runtime': 52490.6157, 'train_samples_per_second': 6.415, 'train_steps_per_second': 0.802, 'total_flos': 4.494459940300656e+17, 'train_loss': 0.22266500411626633, 'epoch': 5.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./r_task',\n",
    "    #learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=200,\n",
    "    logging_steps=200,\n",
    "   \n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16762135-f4cc-4626-a4cb-361567e26284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
