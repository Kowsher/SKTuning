{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1510cc-2c33-48ce-b22e-39a7df77e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1010b1-ee7d-4e50-9deb-d853bd99214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5be269-962b-40e7-820c-4bd15233e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers accelerate datasets scikit-learn sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6dbf99-0f8e-4e6e-be86-2218da3dffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"PyTorch b model.\"\"\"\n",
    "\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, LayerNorm, MSELoss\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers.file_utils import add_code_sample_docstrings, add_start_docstrings, add_start_docstrings_to_model_forward\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.utils import logging\n",
    "from transformers import BloomConfig, BloomPreTrainedModel, BloomModel, AutoConfig, PreTrainedModel, AutoModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutput, Seq2SeqLMOutput\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PrefixEncoder(torch.nn.Module):\n",
    "    def __init__(self, config, transfromer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout)\n",
    "        self.transfromer=transfromer\n",
    "\n",
    "        word_embeddings = transfromer.word_embeddings\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(config._name_or_path)\n",
    "        \n",
    "        init_token_ids = tokenizer(config.text, return_tensors='pt')['input_ids']\n",
    "        print(\"Prefix sequence length: \", init_token_ids.shape[1])\n",
    "        tokenizer=None\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(init_token_ids.shape[1], config.hidden_size)\n",
    "\n",
    "        if config.transform==True:\n",
    "            self.transform = nn.Linear(config.n_embd, config.n_embd, bias=False)\n",
    "        else:\n",
    "            self.transform=None\n",
    "     \n",
    "        init_token_ids = torch.LongTensor(init_token_ids).to(word_embeddings.weight.device)\n",
    "\n",
    "        word_embedding_weights = word_embeddings(init_token_ids).detach().clone()\n",
    "        word_embedding_weights = word_embedding_weights.to(torch.float32)\n",
    "        #print('word_embedding_weights', word_embedding_weights.shape)\n",
    "        #print('word_embedding_weights', word_embedding_weights.squeeze(0).shape)\n",
    "        self.embedding.weight = torch.nn.Parameter(word_embedding_weights.squeeze(0))  \n",
    "        global virtual_tokens \n",
    "        virtual_tokens = torch.arange(0, init_token_ids.shape[1])\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        device=None,\n",
    "        batch_size=None,\n",
    "\n",
    "    ):\n",
    "\n",
    "\n",
    "        inputs_embeds = self.embedding(virtual_tokens.to(device))\n",
    "        inputs_embeds=self.dropout(inputs_embeds)\n",
    "        outputs = self.transfromer(\n",
    "            inputs_embeds=inputs_embeds.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        )        \n",
    "        #print('working', outputs.past_key_values)\n",
    "        #print('working', projection)\n",
    "        past_key_values=outputs.past_key_values\n",
    "        if config.transform==True:\n",
    "        # Apply transformations\n",
    "            transformed_key_values = []\n",
    "            for layer in past_key_values:\n",
    "                key, value = layer\n",
    "                #print(key.shape, value.shape)\n",
    "                # Transpose, transform, and transpose back for key\n",
    "                transformed_key = self.transform(key.transpose(1, 2)).transpose(1, 2)\n",
    "                transformed_key=self.dropout(transformed_key)\n",
    "                # Transpose, transform, and transpose back for value\n",
    "                transformed_value = self.transform(value)\n",
    "                transformed_value = self.dropout(transformed_value)\n",
    "                transformed_key_values.append((transformed_key, transformed_value))\n",
    "\n",
    "            transformed_past_key_values = tuple(transformed_key_values)\n",
    "        \n",
    "            return  (transformed_past_key_values, inputs_embeds.shape[0])\n",
    "        else:\n",
    "            return  (past_key_values, inputs_embeds.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "class PrefixForSequenceClassification(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.transformer =  AutoModel.from_pretrained(config._name_or_path)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout)\n",
    "        self.score = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.n_layer = config.num_hidden_layers\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.hidden_size // config.n_head\n",
    "        config.n_embd=self.n_embd\n",
    "\n",
    "        #print('self.prefix_ids', self.prefix_ids)\n",
    "        self.prompt_encoder = PrefixEncoder(config, self.transformer)\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        #print('prefix_ids', prefix_ids)\n",
    "        past_key_values, pre_length =  self.prompt_encoder(self.transformer.device, batch_size)\n",
    "        #print('prompts', prompts.shape)\n",
    "        #print('raw_tokens_embedding', raw_tokens_embedding)\n",
    "        #print('batch_size', batch_size, self.pre_seq_len)\n",
    "        #inputs_embeds = torch.cat((prompts, raw_tokens_embedding), dim=1)\n",
    "        prompt_attention_mask = torch.ones(batch_size, pre_length).to(self.transformer.device)\n",
    "        attention_mask = torch.cat((prompt_attention_mask, attention_mask), dim=1)\n",
    "\n",
    "        outputs = self.transformer(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=return_dict,\n",
    "            past_key_values=past_key_values,\n",
    "        )\n",
    "\n",
    "        \n",
    "        hidden_states = self.dropout(outputs[0])\n",
    "\n",
    "        logits = self.score(hidden_states)\n",
    "        logits = torch.mean(logits, dim=1)\n",
    "\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class PromptEncoder(torch.nn.Module):\n",
    "    def __init__(self, config, word_embeddings):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(config._name_or_path)\n",
    "        \n",
    "        init_token_ids = tokenizer(config.text, return_tensors='pt')['input_ids']\n",
    "        print(\"Prompt sequence length: \", init_token_ids.shape[1])\n",
    "        #print(\"config.pre_seq_len, config.hidden_size\", config.pre_seq_len, config.hidden_size)\n",
    "        tokenizer=None\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(init_token_ids.shape[1], config.hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout)\n",
    "\n",
    "        if config.transform==True:\n",
    "            self.transform = nn.Linear(config.hidden_size, config.hidden_size, bias=False)\n",
    "        else:\n",
    "            self.transform=None\n",
    "            \n",
    "        init_token_ids = torch.LongTensor(init_token_ids).to(word_embeddings.weight.device)\n",
    "\n",
    "        word_embedding_weights = word_embeddings(init_token_ids).detach().clone()\n",
    "        word_embedding_weights = word_embedding_weights.to(torch.float32)\n",
    "        #print('word_embedding_weights', word_embedding_weights.shape)\n",
    "        #print('word_embedding_weights', word_embedding_weights.squeeze(0).shape)\n",
    "        self.embedding.weight = torch.nn.Parameter(word_embedding_weights.squeeze(0))  \n",
    "        global virtual_tokens \n",
    "        virtual_tokens = torch.arange(0, init_token_ids.shape[1])\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        device=None,\n",
    "        batch_size=None,\n",
    "\n",
    "    ):\n",
    "\n",
    "        projection = self.embedding(virtual_tokens.to(device))\n",
    "        projection=self.dropout(projection)\n",
    "        \n",
    "        if config.transform==True:\n",
    "            projection = self.transform(projection)\n",
    "            projection=self.dropout(projection)\n",
    "\n",
    "        return projection.repeat(batch_size, 1, 1)\n",
    "\n",
    "\n",
    "class PromptForSequenceClassification(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.transformer =  AutoModel.from_pretrained(config._name_or_path)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout)\n",
    "        #prefix_ids = config.tokenizer(config.prefix, return_tensors='pt')['input_ids']\n",
    "        #print('prefix_ids', prefix_ids)\n",
    "        self.score = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.n_layer = config.num_hidden_layers\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.hidden_size // config.n_head\n",
    "\n",
    "        #print('self.prefix_ids', self.prefix_ids)\n",
    "        self.prompt_encoder = PromptEncoder(config, self.transformer.word_embeddings )\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        raw_tokens_embedding = self.transformer.word_embeddings (input_ids)\n",
    "        #print('prefix_ids', prefix_ids)\n",
    "        prompts =  self.prompt_encoder(self.transformer.device, batch_size)\n",
    "        #print('prompts', prompts.shape)\n",
    "        #print('raw_tokens_embedding', raw_tokens_embedding)\n",
    "        #print('batch_size', batch_size, self.pre_seq_len)\n",
    "        inputs_embeds = torch.cat((prompts, raw_tokens_embedding), dim=1)\n",
    "        prompt_attention_mask = torch.ones(batch_size, prompts.shape[1]).to(self.transformer.device)\n",
    "        attention_mask = torch.cat((prompt_attention_mask, attention_mask), dim=1)\n",
    "\n",
    "        outputs = self.transformer(\n",
    "            # input_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=return_dict,\n",
    "            # past_key_values=past_key_values,\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "        hidden_states = self.dropout(outputs[0])\n",
    "        logits = self.score(hidden_states)\n",
    "        logits = torch.mean(logits, dim=1)\n",
    "\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class PromptForTokenClassification(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.transformer =  AutoModel.from_pretrained(config._name_or_path)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout)\n",
    "        #prefix_ids = config.tokenizer(config.prefix, return_tensors='pt')['input_ids']\n",
    "        #print('prefix_ids', prefix_ids)\n",
    "        self.score = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.n_layer = config.num_hidden_layers\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.hidden_size // config.n_head\n",
    "\n",
    "        #print('self.prefix_ids', self.prefix_ids)\n",
    "        self.prompt_encoder = PromptEncoder(config, self.transformer.word_embeddings)\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        raw_tokens_embedding = self.transformer.word_embeddings(input_ids)\n",
    "        #print('prefix_ids', prefix_ids)\n",
    "        prompts =  self.prompt_encoder(self.transformer.device, batch_size)\n",
    "        #print('prompts', prompts.shape)\n",
    "        #print('raw_tokens_embedding', raw_tokens_embedding)\n",
    "        #print('batch_size', batch_size, self.pre_seq_len)\n",
    "        inputs_embeds = torch.cat((prompts, raw_tokens_embedding), dim=1)\n",
    "        prompt_attention_mask = torch.ones(batch_size, prompts.shape[1]).to(self.transformer.device)\n",
    "        attention_mask = torch.cat((prompt_attention_mask, attention_mask), dim=1)\n",
    "\n",
    "        outputs = self.transformer(\n",
    "            # input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            # token_type_ids=token_type_ids,\n",
    "            # position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            # past_key_values=past_key_values,\n",
    "        )\n",
    "\n",
    "\n",
    "        hidden_states = outputs[0][:, prompts.shape[1]:, :]\n",
    "        #print('hidden_states', hidden_states.shape)\n",
    "        #print('labels', labels.shape)\n",
    "        \n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        logits = self.score(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # move labels to correct device to enable model parallelism\n",
    "            labels = labels.to(logits.device)\n",
    "            batch_size, seq_length = labels.shape\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(\n",
    "                logits.view(batch_size * seq_length, self.num_labels), labels.view(batch_size * seq_length)\n",
    "            )\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + transformer_outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b588c-fae3-42e6-ba9c-6d1eda5770fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52654071-04b0-4623-9948-1d249877efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikiann\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2154b825-24b1-4efc-9491-5f50d1e1abfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = dataset[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f5b358-4069-4d41-929c-8a7b74219634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name=\"tiiuae/falcon-7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efec15cd-f9b0-4e8d-85e9-0cb9f456d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"],max_length=128, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fb6e2-8c86-424a-a49a-c017310163bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d390576a-c7ba-43e2-ab0a-efdeb54990a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b705ed919b445abdd7ad40e913c2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897134f150ce4a1e80ba47fd4b4595be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c7ce92002c487bbf545e3e42e8aa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f914c34-171f-4f48-863c-047844b5248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc5b819-27df-4390-875b-5600be17ce8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FalconConfig {\n",
       "  \"_name_or_path\": \"tiiuae/falcon-7b-instruct\",\n",
       "  \"alibi\": false,\n",
       "  \"apply_residual_connection_post_layernorm\": false,\n",
       "  \"architectures\": [\n",
       "    \"FalconForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"tiiuae/falcon-7b-instruct--configuration_falcon.FalconConfig\",\n",
       "    \"AutoModel\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconModel\",\n",
       "    \"AutoModelForCausalLM\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForCausalLM\",\n",
       "    \"AutoModelForQuestionAnswering\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForQuestionAnswering\",\n",
       "    \"AutoModelForSequenceClassification\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForSequenceClassification\",\n",
       "    \"AutoModelForTokenClassification\": \"tiiuae/falcon-7b-instruct--modeling_falcon.FalconForTokenClassification\"\n",
       "  },\n",
       "  \"bias\": false,\n",
       "  \"bos_token_id\": 11,\n",
       "  \"eos_token_id\": 11,\n",
       "  \"hidden_dropout\": 0.0,\n",
       "  \"hidden_size\": 4544,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"falcon\",\n",
       "  \"multi_query\": true,\n",
       "  \"new_decoder_architecture\": false,\n",
       "  \"num_attention_heads\": 71,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_kv_heads\": 71,\n",
       "  \"parallel_attn\": true,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 65024\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5805e914-c233-434e-af47-5cfa056fa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config._name_or_path=model_name\n",
    "config.hidden_size=4544\n",
    "config.num_hidden_layers=32\n",
    "config.n_head=71\n",
    "config.num_labels=7\n",
    "config.pad_token_id=tokenizer.pad_token_id\n",
    "config.hidden_dropout = 0.1\n",
    "config.transform=False\n",
    "config.text='classify the token of the text:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3020a8-b7b7-4ff7-985c-e5b573dcfe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d677f06b1677465faece23a35b90d938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt sequence length:  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472e29458882496b8c58399406b11549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PromptForTokenClassification were not initialized from the model checkpoint at tiiuae/falcon-7b-instruct and are newly initialized: ['score.bias', 'score.weight', 'prompt_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#from falconSKT import  PrefixForSequenceClassification, PromptForSequenceClassification\n",
    "\n",
    "model = PromptForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccde7f-486d-4459-b978-ad79e797ed32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766c3dd-9068-415d-a203-7ab14de101e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of parameters in the model\n",
    "total_parameters = model.num_parameters()\n",
    "\n",
    "# Total number of trainable parameters in the model\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Calculate the percentage of trainable parameters\n",
    "percentage_trainable = (trainable_parameters / total_parameters) * 100\n",
    "\n",
    "print(f\"Total Parameters: {total_parameters}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters}\")\n",
    "print(f\"Percentage Trainable: {percentage_trainable:.20f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fa56762-1650-452e-a1ee-8e27c03e6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb1fac9-ac0a-4b66-a8a6-c942e34ab83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97598ece-04d3-437f-a348-efec246b44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9139' max='16670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9139/16670 2:49:17 < 2:19:32, 0.90 it/s, Epoch 2.74/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.256900</td>\n",
       "      <td>0.847661</td>\n",
       "      <td>0.198880</td>\n",
       "      <td>0.278581</td>\n",
       "      <td>0.232079</td>\n",
       "      <td>0.720575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.716461</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>0.366789</td>\n",
       "      <td>0.299231</td>\n",
       "      <td>0.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.646363</td>\n",
       "      <td>0.283837</td>\n",
       "      <td>0.404058</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.781932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.608301</td>\n",
       "      <td>0.300665</td>\n",
       "      <td>0.432405</td>\n",
       "      <td>0.354698</td>\n",
       "      <td>0.795207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>0.584105</td>\n",
       "      <td>0.315594</td>\n",
       "      <td>0.445428</td>\n",
       "      <td>0.369435</td>\n",
       "      <td>0.801370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.587900</td>\n",
       "      <td>0.571816</td>\n",
       "      <td>0.327057</td>\n",
       "      <td>0.464926</td>\n",
       "      <td>0.383991</td>\n",
       "      <td>0.807820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.573900</td>\n",
       "      <td>0.559108</td>\n",
       "      <td>0.323874</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.381448</td>\n",
       "      <td>0.810902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.549083</td>\n",
       "      <td>0.337560</td>\n",
       "      <td>0.476869</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.815181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.541778</td>\n",
       "      <td>0.346495</td>\n",
       "      <td>0.489316</td>\n",
       "      <td>0.405703</td>\n",
       "      <td>0.818861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>0.541678</td>\n",
       "      <td>0.344363</td>\n",
       "      <td>0.494208</td>\n",
       "      <td>0.405897</td>\n",
       "      <td>0.820308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>0.534134</td>\n",
       "      <td>0.349303</td>\n",
       "      <td>0.488884</td>\n",
       "      <td>0.407472</td>\n",
       "      <td>0.820446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>0.525850</td>\n",
       "      <td>0.350519</td>\n",
       "      <td>0.497949</td>\n",
       "      <td>0.411426</td>\n",
       "      <td>0.824126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.521663</td>\n",
       "      <td>0.357241</td>\n",
       "      <td>0.507447</td>\n",
       "      <td>0.419297</td>\n",
       "      <td>0.825511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.525100</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>0.347122</td>\n",
       "      <td>0.490251</td>\n",
       "      <td>0.406454</td>\n",
       "      <td>0.823577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.518960</td>\n",
       "      <td>0.347425</td>\n",
       "      <td>0.498453</td>\n",
       "      <td>0.409456</td>\n",
       "      <td>0.825573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.514661</td>\n",
       "      <td>0.352627</td>\n",
       "      <td>0.503202</td>\n",
       "      <td>0.414668</td>\n",
       "      <td>0.827233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.510759</td>\n",
       "      <td>0.359175</td>\n",
       "      <td>0.507662</td>\n",
       "      <td>0.420701</td>\n",
       "      <td>0.828742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.507492</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.513418</td>\n",
       "      <td>0.424964</td>\n",
       "      <td>0.829690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./r_task/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./r_task/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./r_task',\n",
    "    #learning_rate=1e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "   \n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    " \n",
    "\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf5237-4f35-4592-beb7-28a80d52d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset[\"train\"]['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01096e-1c2d-40dd-a93f-9e3fb2a3fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ada0e-778f-4b3f-9ec9-bf0b5859fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20525740-83f7-4df9-b153-b701637964fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
